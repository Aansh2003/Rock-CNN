{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfd88319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images-size: torch.Size([8, 3, 256, 256])\n",
      "out-size: torch.Size([3, 260, 2066])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import *\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import copy\n",
    "import os\n",
    "\n",
    "batch_size = 8\n",
    "learning_rate = 1e-3\n",
    "\n",
    "transforms = transforms.Compose(\n",
    "[\n",
    "    transforms.Resize((256,256)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_dataset = datasets.ImageFolder(root='C:/Datasets/new_rock/train', transform=transforms)\n",
    "test_dataset = datasets.ImageFolder(root='C:/Datasets/new_rock/test', transform=transforms)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def imshow(inp, title=None):\n",
    "    \n",
    "    inp = inp.cpu() if device else inp\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    \n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    \n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)\n",
    "    \n",
    "images, labels = next(iter(train_dataloader)) \n",
    "print(\"images-size:\", images.shape)\n",
    "\n",
    "out = torchvision.utils.make_grid(images)\n",
    "print(\"out-size:\", out.shape)\n",
    "\n",
    "imshow(out, title=[train_dataset.classes[x] for x in labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95484941",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (6): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (7): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (6): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (7): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (8): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (9): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (10): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (11): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (12): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (13): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (14): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (15): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (16): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (17): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (18): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (19): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (20): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (21): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (22): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (23): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (24): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (25): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (26): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (27): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (28): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (29): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (30): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (31): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (32): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (33): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (34): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (35): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision.models import resnet152, ResNet152_Weights\n",
    "\n",
    "\n",
    "weights = ResNet152_Weights.DEFAULT\n",
    "model = resnet152(weights=weights)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b964f7f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (6): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (7): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (6): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (7): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (8): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (9): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (10): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (11): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (12): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (13): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (14): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (15): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (16): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (17): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (18): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (19): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (20): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (21): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (22): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (23): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (24): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (25): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (26): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (27): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (28): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (29): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (30): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (31): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (32): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (33): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (34): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (35): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=128, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.0001, momentum=0.9)\n",
    "\n",
    "def accuracy(out, labels):\n",
    "    _,pred = torch.max(out, dim=1)\n",
    "    return torch.sum(pred==labels).item()\n",
    "\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 128)\n",
    "model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "743e3c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "\n",
      "Epoch [1/100], Step [0/243], Loss: 4.8835\n",
      "Epoch [1/100], Step [20/243], Loss: 4.8479\n",
      "Epoch [1/100], Step [40/243], Loss: 4.8437\n",
      "Epoch [1/100], Step [60/243], Loss: 4.9102\n",
      "Epoch [1/100], Step [80/243], Loss: 4.8553\n",
      "Epoch [1/100], Step [100/243], Loss: 4.8903\n",
      "Epoch [1/100], Step [120/243], Loss: 4.8228\n",
      "Epoch [1/100], Step [140/243], Loss: 4.8578\n",
      "Epoch [1/100], Step [160/243], Loss: 4.8497\n",
      "Epoch [1/100], Step [180/243], Loss: 4.8332\n",
      "Epoch [1/100], Step [200/243], Loss: 4.8741\n",
      "Epoch [1/100], Step [220/243], Loss: 4.8489\n",
      "Epoch [1/100], Step [240/243], Loss: 4.8982\n",
      "\n",
      "train-loss: 4.8511, train-acc: 0.6691\n",
      "validation loss: 4.8459, validation acc: 0.7519\n",
      "\n",
      "Improvement-Detected, save-model\n",
      "Epoch 2\n",
      "\n",
      "Epoch [2/100], Step [0/243], Loss: 4.8690\n",
      "Epoch [2/100], Step [20/243], Loss: 4.9432\n",
      "Epoch [2/100], Step [40/243], Loss: 4.7801\n",
      "Epoch [2/100], Step [60/243], Loss: 4.8100\n",
      "Epoch [2/100], Step [80/243], Loss: 4.8097\n",
      "Epoch [2/100], Step [100/243], Loss: 4.8425\n",
      "Epoch [2/100], Step [120/243], Loss: 4.8939\n",
      "Epoch [2/100], Step [140/243], Loss: 4.8695\n",
      "Epoch [2/100], Step [160/243], Loss: 4.8273\n",
      "Epoch [2/100], Step [180/243], Loss: 4.8108\n",
      "Epoch [2/100], Step [200/243], Loss: 4.8111\n",
      "Epoch [2/100], Step [220/243], Loss: 4.7761\n",
      "Epoch [2/100], Step [240/243], Loss: 4.7622\n",
      "\n",
      "train-loss: 4.8383, train-acc: 0.8235\n",
      "validation loss: 4.8345, validation acc: 0.0000\n",
      "\n",
      "Improvement-Detected, save-model\n",
      "Epoch 3\n",
      "\n",
      "Epoch [3/100], Step [0/243], Loss: 4.8436\n",
      "Epoch [3/100], Step [20/243], Loss: 4.7553\n",
      "Epoch [3/100], Step [40/243], Loss: 4.8196\n",
      "Epoch [3/100], Step [60/243], Loss: 4.8123\n",
      "Epoch [3/100], Step [80/243], Loss: 4.7765\n",
      "Epoch [3/100], Step [100/243], Loss: 4.8658\n",
      "Epoch [3/100], Step [120/243], Loss: 4.8196\n",
      "Epoch [3/100], Step [140/243], Loss: 4.7785\n",
      "Epoch [3/100], Step [160/243], Loss: 4.8261\n",
      "Epoch [3/100], Step [180/243], Loss: 4.8569\n",
      "Epoch [3/100], Step [200/243], Loss: 4.7425\n",
      "Epoch [3/100], Step [220/243], Loss: 4.7472\n",
      "Epoch [3/100], Step [240/243], Loss: 4.7667\n",
      "\n",
      "train-loss: 4.8260, train-acc: 2.0072\n",
      "validation loss: 4.8290, validation acc: 0.7519\n",
      "\n",
      "Improvement-Detected, save-model\n",
      "Epoch 4\n",
      "\n",
      "Epoch [4/100], Step [0/243], Loss: 4.7526\n",
      "Epoch [4/100], Step [20/243], Loss: 4.7432\n",
      "Epoch [4/100], Step [40/243], Loss: 4.7893\n",
      "Epoch [4/100], Step [60/243], Loss: 4.7679\n",
      "Epoch [4/100], Step [80/243], Loss: 4.7479\n",
      "Epoch [4/100], Step [100/243], Loss: 4.7619\n",
      "Epoch [4/100], Step [120/243], Loss: 4.7237\n",
      "Epoch [4/100], Step [140/243], Loss: 4.7832\n",
      "Epoch [4/100], Step [160/243], Loss: 4.7215\n",
      "Epoch [4/100], Step [180/243], Loss: 4.7243\n",
      "Epoch [4/100], Step [200/243], Loss: 4.7747\n",
      "Epoch [4/100], Step [220/243], Loss: 4.7040\n",
      "Epoch [4/100], Step [240/243], Loss: 4.7705\n",
      "\n",
      "train-loss: 4.8133, train-acc: 1.9557\n",
      "validation loss: 4.8177, validation acc: 2.2556\n",
      "\n",
      "Improvement-Detected, save-model\n",
      "Epoch 5\n",
      "\n",
      "Epoch [5/100], Step [0/243], Loss: 4.7625\n",
      "Epoch [5/100], Step [20/243], Loss: 4.8180\n",
      "Epoch [5/100], Step [40/243], Loss: 4.7622\n",
      "Epoch [5/100], Step [60/243], Loss: 4.7364\n",
      "Epoch [5/100], Step [80/243], Loss: 4.6951\n",
      "Epoch [5/100], Step [100/243], Loss: 4.6802\n",
      "Epoch [5/100], Step [120/243], Loss: 4.6987\n",
      "Epoch [5/100], Step [140/243], Loss: 4.6936\n",
      "Epoch [5/100], Step [160/243], Loss: 4.8080\n",
      "Epoch [5/100], Step [180/243], Loss: 4.7827\n",
      "Epoch [5/100], Step [200/243], Loss: 4.7623\n",
      "Epoch [5/100], Step [220/243], Loss: 4.8049\n",
      "Epoch [5/100], Step [240/243], Loss: 4.7910\n",
      "\n",
      "train-loss: 4.8000, train-acc: 4.7864\n",
      "validation loss: 4.8056, validation acc: 4.5113\n",
      "\n",
      "Improvement-Detected, save-model\n",
      "Epoch 6\n",
      "\n",
      "Epoch [6/100], Step [0/243], Loss: 4.8049\n",
      "Epoch [6/100], Step [20/243], Loss: 4.8012\n",
      "Epoch [6/100], Step [40/243], Loss: 4.7475\n",
      "Epoch [6/100], Step [60/243], Loss: 4.7676\n",
      "Epoch [6/100], Step [80/243], Loss: 4.6805\n",
      "Epoch [6/100], Step [100/243], Loss: 4.7041\n",
      "Epoch [6/100], Step [120/243], Loss: 4.6482\n",
      "Epoch [6/100], Step [140/243], Loss: 4.7038\n",
      "Epoch [6/100], Step [160/243], Loss: 4.7593\n",
      "Epoch [6/100], Step [180/243], Loss: 4.6427\n",
      "Epoch [6/100], Step [200/243], Loss: 4.5884\n",
      "Epoch [6/100], Step [220/243], Loss: 4.7478\n",
      "Epoch [6/100], Step [240/243], Loss: 4.7646\n",
      "\n",
      "train-loss: 4.7857, train-acc: 6.0731\n",
      "validation loss: 4.7927, validation acc: 11.2782\n",
      "\n",
      "Improvement-Detected, save-model\n",
      "Epoch 7\n",
      "\n",
      "Epoch [7/100], Step [0/243], Loss: 4.7676\n",
      "Epoch [7/100], Step [20/243], Loss: 4.8004\n",
      "Epoch [7/100], Step [40/243], Loss: 4.8371\n",
      "Epoch [7/100], Step [60/243], Loss: 4.6844\n",
      "Epoch [7/100], Step [80/243], Loss: 4.6810\n",
      "Epoch [7/100], Step [100/243], Loss: 4.7943\n",
      "Epoch [7/100], Step [120/243], Loss: 4.6353\n",
      "Epoch [7/100], Step [140/243], Loss: 4.5473\n",
      "Epoch [7/100], Step [160/243], Loss: 4.8156\n",
      "Epoch [7/100], Step [180/243], Loss: 4.6023\n",
      "Epoch [7/100], Step [200/243], Loss: 4.6384\n",
      "Epoch [7/100], Step [220/243], Loss: 4.6496\n",
      "Epoch [7/100], Step [240/243], Loss: 4.6053\n",
      "\n",
      "train-loss: 4.7700, train-acc: 10.6536\n",
      "validation loss: 4.7799, validation acc: 13.5338\n",
      "\n",
      "Improvement-Detected, save-model\n",
      "Epoch 8\n",
      "\n",
      "Epoch [8/100], Step [0/243], Loss: 4.7413\n",
      "Epoch [8/100], Step [20/243], Loss: 4.5667\n",
      "Epoch [8/100], Step [40/243], Loss: 4.6681\n",
      "Epoch [8/100], Step [60/243], Loss: 4.6085\n",
      "Epoch [8/100], Step [80/243], Loss: 4.6070\n",
      "Epoch [8/100], Step [100/243], Loss: 4.6113\n",
      "Epoch [8/100], Step [120/243], Loss: 4.6265\n",
      "Epoch [8/100], Step [140/243], Loss: 4.7359\n",
      "Epoch [8/100], Step [160/243], Loss: 4.6690\n",
      "Epoch [8/100], Step [180/243], Loss: 4.4798\n",
      "Epoch [8/100], Step [200/243], Loss: 4.6961\n",
      "Epoch [8/100], Step [220/243], Loss: 4.5796\n",
      "Epoch [8/100], Step [240/243], Loss: 4.4757\n",
      "\n",
      "train-loss: 4.7525, train-acc: 15.1312\n",
      "validation loss: 4.7644, validation acc: 16.5414\n",
      "\n",
      "Improvement-Detected, save-model\n",
      "Epoch 9\n",
      "\n",
      "Epoch [9/100], Step [0/243], Loss: 4.6618\n",
      "Epoch [9/100], Step [20/243], Loss: 4.5458\n",
      "Epoch [9/100], Step [40/243], Loss: 4.6218\n",
      "Epoch [9/100], Step [60/243], Loss: 4.6837\n",
      "Epoch [9/100], Step [80/243], Loss: 4.5526\n",
      "Epoch [9/100], Step [100/243], Loss: 4.5596\n",
      "Epoch [9/100], Step [120/243], Loss: 4.5615\n",
      "Epoch [9/100], Step [140/243], Loss: 4.6362\n",
      "Epoch [9/100], Step [160/243], Loss: 4.5984\n",
      "Epoch [9/100], Step [180/243], Loss: 4.5712\n",
      "Epoch [9/100], Step [200/243], Loss: 4.5483\n",
      "Epoch [9/100], Step [220/243], Loss: 4.4143\n",
      "Epoch [9/100], Step [240/243], Loss: 4.6144\n",
      "\n",
      "train-loss: 4.7322, train-acc: 21.5646\n",
      "validation loss: 4.7490, validation acc: 21.0526\n",
      "\n",
      "Improvement-Detected, save-model\n",
      "Epoch 10\n",
      "\n",
      "Epoch [10/100], Step [0/243], Loss: 4.5417\n",
      "Epoch [10/100], Step [20/243], Loss: 4.5835\n",
      "Epoch [10/100], Step [40/243], Loss: 4.5337\n",
      "Epoch [10/100], Step [60/243], Loss: 4.5513\n",
      "Epoch [10/100], Step [80/243], Loss: 4.3655\n",
      "Epoch [10/100], Step [100/243], Loss: 4.3047\n",
      "Epoch [10/100], Step [120/243], Loss: 4.5283\n",
      "Epoch [10/100], Step [140/243], Loss: 4.6372\n",
      "Epoch [10/100], Step [160/243], Loss: 4.5002\n",
      "Epoch [10/100], Step [180/243], Loss: 4.6336\n",
      "Epoch [10/100], Step [200/243], Loss: 4.4514\n",
      "Epoch [10/100], Step [220/243], Loss: 4.5114\n",
      "Epoch [10/100], Step [240/243], Loss: 4.5184\n",
      "\n",
      "train-loss: 4.7077, train-acc: 29.4905\n",
      "validation loss: 4.7286, validation acc: 29.3233\n",
      "\n",
      "Improvement-Detected, save-model\n",
      "Epoch 11\n",
      "\n",
      "Epoch [11/100], Step [0/243], Loss: 4.4182\n",
      "Epoch [11/100], Step [20/243], Loss: 4.4800\n",
      "Epoch [11/100], Step [40/243], Loss: 4.4123\n",
      "Epoch [11/100], Step [60/243], Loss: 4.5562\n",
      "Epoch [11/100], Step [80/243], Loss: 4.5112\n",
      "Epoch [11/100], Step [100/243], Loss: 4.2505\n",
      "Epoch [11/100], Step [120/243], Loss: 4.3712\n",
      "Epoch [11/100], Step [140/243], Loss: 4.5168\n",
      "Epoch [11/100], Step [160/243], Loss: 4.2978\n",
      "Epoch [11/100], Step [180/243], Loss: 4.4031\n",
      "Epoch [11/100], Step [200/243], Loss: 4.3440\n",
      "Epoch [11/100], Step [220/243], Loss: 4.3558\n",
      "Epoch [11/100], Step [240/243], Loss: 4.4882\n",
      "\n",
      "train-loss: 4.6779, train-acc: 35.8209\n",
      "validation loss: 4.7047, validation acc: 33.0827\n",
      "\n",
      "Improvement-Detected, save-model\n",
      "Epoch 12\n",
      "\n",
      "Epoch [12/100], Step [0/243], Loss: 4.1128\n",
      "Epoch [12/100], Step [20/243], Loss: 4.2789\n",
      "Epoch [12/100], Step [40/243], Loss: 4.0052\n",
      "Epoch [12/100], Step [60/243], Loss: 4.1049\n",
      "Epoch [12/100], Step [80/243], Loss: 4.4236\n",
      "Epoch [12/100], Step [100/243], Loss: 4.2637\n",
      "Epoch [12/100], Step [120/243], Loss: 4.0332\n",
      "Epoch [12/100], Step [140/243], Loss: 4.2295\n",
      "Epoch [12/100], Step [160/243], Loss: 4.2320\n",
      "Epoch [12/100], Step [180/243], Loss: 4.2473\n",
      "Epoch [12/100], Step [200/243], Loss: 4.4489\n",
      "Epoch [12/100], Step [220/243], Loss: 4.3075\n",
      "Epoch [12/100], Step [240/243], Loss: 4.4464\n",
      "\n",
      "train-loss: 4.6412, train-acc: 41.9969\n",
      "validation loss: 4.6759, validation acc: 35.3383\n",
      "\n",
      "Improvement-Detected, save-model\n",
      "Epoch 13\n",
      "\n",
      "Epoch [13/100], Step [0/243], Loss: 4.2085\n",
      "Epoch [13/100], Step [20/243], Loss: 4.4762\n",
      "Epoch [13/100], Step [40/243], Loss: 3.9863\n",
      "Epoch [13/100], Step [60/243], Loss: 3.8742\n",
      "Epoch [13/100], Step [80/243], Loss: 4.1155\n",
      "Epoch [13/100], Step [100/243], Loss: 3.9884\n",
      "Epoch [13/100], Step [120/243], Loss: 4.0767\n",
      "Epoch [13/100], Step [140/243], Loss: 4.1683\n",
      "Epoch [13/100], Step [160/243], Loss: 3.8347\n",
      "Epoch [13/100], Step [180/243], Loss: 4.0871\n",
      "Epoch [13/100], Step [200/243], Loss: 4.0669\n",
      "Epoch [13/100], Step [220/243], Loss: 4.1695\n",
      "Epoch [13/100], Step [240/243], Loss: 3.9416\n",
      "\n",
      "train-loss: 4.5964, train-acc: 45.2908\n",
      "validation loss: 4.6397, validation acc: 42.8571\n",
      "\n",
      "Improvement-Detected, save-model\n",
      "Epoch 14\n",
      "\n",
      "Epoch [14/100], Step [0/243], Loss: 4.0457\n",
      "Epoch [14/100], Step [20/243], Loss: 3.9073\n",
      "Epoch [14/100], Step [40/243], Loss: 3.8260\n",
      "Epoch [14/100], Step [60/243], Loss: 3.8465\n",
      "Epoch [14/100], Step [80/243], Loss: 3.7509\n",
      "Epoch [14/100], Step [100/243], Loss: 3.9475\n",
      "Epoch [14/100], Step [120/243], Loss: 4.1144\n",
      "Epoch [14/100], Step [140/243], Loss: 3.8825\n",
      "Epoch [14/100], Step [160/243], Loss: 3.7121\n",
      "Epoch [14/100], Step [180/243], Loss: 3.7928\n",
      "Epoch [14/100], Step [200/243], Loss: 4.0280\n",
      "Epoch [14/100], Step [220/243], Loss: 3.8148\n",
      "Epoch [14/100], Step [240/243], Loss: 3.7746\n",
      "\n",
      "train-loss: 4.5445, train-acc: 48.8420\n",
      "validation loss: 4.6010, validation acc: 39.8496\n",
      "\n",
      "Improvement-Detected, save-model\n",
      "Epoch 15\n",
      "\n",
      "Epoch [15/100], Step [0/243], Loss: 4.2173\n",
      "Epoch [15/100], Step [20/243], Loss: 3.7990\n",
      "Epoch [15/100], Step [40/243], Loss: 3.2845\n",
      "Epoch [15/100], Step [60/243], Loss: 3.9228\n",
      "Epoch [15/100], Step [80/243], Loss: 3.5095\n",
      "Epoch [15/100], Step [100/243], Loss: 3.5963\n",
      "Epoch [15/100], Step [120/243], Loss: 3.4100\n",
      "Epoch [15/100], Step [140/243], Loss: 3.3776\n",
      "Epoch [15/100], Step [160/243], Loss: 3.5907\n",
      "Epoch [15/100], Step [180/243], Loss: 3.8863\n",
      "Epoch [15/100], Step [200/243], Loss: 3.3854\n",
      "Epoch [15/100], Step [220/243], Loss: 3.1015\n",
      "Epoch [15/100], Step [240/243], Loss: 3.4283\n",
      "\n",
      "train-loss: 4.4868, train-acc: 50.2831\n",
      "validation loss: 4.5472, validation acc: 45.1128\n",
      "\n",
      "Improvement-Detected, save-model\n",
      "Epoch 16\n",
      "\n",
      "Epoch [16/100], Step [0/243], Loss: 3.6013\n",
      "Epoch [16/100], Step [20/243], Loss: 3.6510\n",
      "Epoch [16/100], Step [40/243], Loss: 3.4152\n",
      "Epoch [16/100], Step [60/243], Loss: 3.6803\n",
      "Epoch [16/100], Step [80/243], Loss: 3.2167\n",
      "Epoch [16/100], Step [100/243], Loss: 3.7214\n",
      "Epoch [16/100], Step [120/243], Loss: 3.2221\n",
      "Epoch [16/100], Step [140/243], Loss: 3.7546\n",
      "Epoch [16/100], Step [160/243], Loss: 3.3321\n",
      "Epoch [16/100], Step [180/243], Loss: 3.8008\n",
      "Epoch [16/100], Step [200/243], Loss: 3.2523\n",
      "Epoch [16/100], Step [220/243], Loss: 3.2941\n",
      "Epoch [16/100], Step [240/243], Loss: 2.9425\n",
      "\n",
      "train-loss: 4.4251, train-acc: 51.2609\n",
      "validation loss: 4.4931, validation acc: 48.8722\n",
      "\n",
      "Improvement-Detected, save-model\n",
      "Epoch 17\n",
      "\n",
      "Epoch [17/100], Step [0/243], Loss: 3.5950\n",
      "Epoch [17/100], Step [20/243], Loss: 3.5309\n",
      "Epoch [17/100], Step [40/243], Loss: 3.3612\n",
      "Epoch [17/100], Step [60/243], Loss: 3.2379\n",
      "Epoch [17/100], Step [80/243], Loss: 3.1888\n",
      "Epoch [17/100], Step [100/243], Loss: 3.5295\n",
      "Epoch [17/100], Step [120/243], Loss: 2.6646\n",
      "Epoch [17/100], Step [140/243], Loss: 4.0023\n",
      "Epoch [17/100], Step [160/243], Loss: 3.4914\n",
      "Epoch [17/100], Step [180/243], Loss: 3.0414\n",
      "Epoch [17/100], Step [200/243], Loss: 3.4454\n",
      "Epoch [17/100], Step [220/243], Loss: 2.8963\n",
      "Epoch [17/100], Step [240/243], Loss: 3.5572\n",
      "\n",
      "train-loss: 4.3610, train-acc: 53.4740\n",
      "validation loss: 4.4345, validation acc: 48.8722\n",
      "\n",
      "Improvement-Detected, save-model\n",
      "Epoch 18\n",
      "\n",
      "Epoch [18/100], Step [0/243], Loss: 3.2103\n",
      "Epoch [18/100], Step [20/243], Loss: 3.2693\n",
      "Epoch [18/100], Step [40/243], Loss: 3.2203\n",
      "Epoch [18/100], Step [60/243], Loss: 3.3609\n",
      "Epoch [18/100], Step [80/243], Loss: 3.2211\n",
      "Epoch [18/100], Step [100/243], Loss: 3.1856\n",
      "Epoch [18/100], Step [120/243], Loss: 3.3219\n",
      "Epoch [18/100], Step [140/243], Loss: 3.4853\n",
      "Epoch [18/100], Step [160/243], Loss: 3.1859\n",
      "Epoch [18/100], Step [180/243], Loss: 3.4157\n",
      "Epoch [18/100], Step [200/243], Loss: 2.8269\n",
      "Epoch [18/100], Step [220/243], Loss: 3.7141\n",
      "Epoch [18/100], Step [240/243], Loss: 2.9055\n",
      "\n",
      "train-loss: 4.2942, train-acc: 55.4812\n",
      "validation loss: 4.3709, validation acc: 52.6316\n",
      "\n",
      "Improvement-Detected, save-model\n",
      "Epoch 19\n",
      "\n",
      "Epoch [19/100], Step [0/243], Loss: 3.9449\n",
      "Epoch [19/100], Step [20/243], Loss: 2.9114\n",
      "Epoch [19/100], Step [40/243], Loss: 2.8312\n",
      "Epoch [19/100], Step [60/243], Loss: 3.0586\n",
      "Epoch [19/100], Step [80/243], Loss: 3.2135\n",
      "Epoch [19/100], Step [100/243], Loss: 2.3601\n",
      "Epoch [19/100], Step [120/243], Loss: 2.5255\n",
      "Epoch [19/100], Step [140/243], Loss: 3.8159\n",
      "Epoch [19/100], Step [160/243], Loss: 3.2401\n",
      "Epoch [19/100], Step [180/243], Loss: 2.1531\n",
      "Epoch [19/100], Step [200/243], Loss: 2.6732\n",
      "Epoch [19/100], Step [220/243], Loss: 2.6397\n",
      "Epoch [19/100], Step [240/243], Loss: 2.8713\n",
      "\n",
      "train-loss: 4.2251, train-acc: 57.7458\n",
      "validation loss: 4.3049, validation acc: 53.3835\n",
      "\n",
      "Improvement-Detected, save-model\n",
      "Epoch 20\n",
      "\n",
      "Epoch [20/100], Step [0/243], Loss: 2.5112\n",
      "Epoch [20/100], Step [20/243], Loss: 3.1127\n",
      "Epoch [20/100], Step [40/243], Loss: 3.5841\n",
      "Epoch [20/100], Step [60/243], Loss: 2.4200\n",
      "Epoch [20/100], Step [80/243], Loss: 2.5287\n",
      "Epoch [20/100], Step [100/243], Loss: 3.3190\n",
      "Epoch [20/100], Step [120/243], Loss: 2.6104\n",
      "Epoch [20/100], Step [140/243], Loss: 2.1558\n",
      "Epoch [20/100], Step [160/243], Loss: 2.2150\n",
      "Epoch [20/100], Step [180/243], Loss: 2.4795\n",
      "Epoch [20/100], Step [200/243], Loss: 2.8692\n",
      "Epoch [20/100], Step [220/243], Loss: 2.9081\n",
      "Epoch [20/100], Step [240/243], Loss: 3.0760\n",
      "\n",
      "train-loss: 4.1538, train-acc: 60.3191\n",
      "validation loss: 4.2433, validation acc: 53.3835\n",
      "\n",
      "Improvement-Detected, save-model\n",
      "Epoch 21\n",
      "\n",
      "Epoch [21/100], Step [0/243], Loss: 3.1285\n",
      "Epoch [21/100], Step [20/243], Loss: 2.6357\n",
      "Epoch [21/100], Step [40/243], Loss: 2.8442\n",
      "Epoch [21/100], Step [60/243], Loss: 2.2290\n",
      "Epoch [21/100], Step [80/243], Loss: 3.3002\n",
      "Epoch [21/100], Step [100/243], Loss: 3.0118\n",
      "Epoch [21/100], Step [120/243], Loss: 2.3386\n",
      "Epoch [21/100], Step [140/243], Loss: 2.4434\n",
      "Epoch [21/100], Step [160/243], Loss: 2.8038\n",
      "Epoch [21/100], Step [180/243], Loss: 1.5834\n",
      "Epoch [21/100], Step [200/243], Loss: 2.6088\n",
      "Epoch [21/100], Step [220/243], Loss: 2.5365\n",
      "Epoch [21/100], Step [240/243], Loss: 2.6905\n",
      "\n",
      "train-loss: 4.0821, train-acc: 60.0103\n",
      "validation loss: 4.1808, validation acc: 56.3910\n",
      "\n",
      "Improvement-Detected, save-model\n",
      "Epoch 22\n",
      "\n",
      "Epoch [22/100], Step [0/243], Loss: 3.4236\n",
      "Epoch [22/100], Step [20/243], Loss: 2.6502\n",
      "Epoch [22/100], Step [40/243], Loss: 2.3230\n",
      "Epoch [22/100], Step [60/243], Loss: 2.5429\n",
      "Epoch [22/100], Step [80/243], Loss: 2.6500\n",
      "Epoch [22/100], Step [100/243], Loss: 2.8777\n",
      "Epoch [22/100], Step [120/243], Loss: 2.1013\n",
      "Epoch [22/100], Step [140/243], Loss: 2.2217\n",
      "Epoch [22/100], Step [160/243], Loss: 2.2971\n",
      "Epoch [22/100], Step [180/243], Loss: 1.9540\n",
      "Epoch [22/100], Step [200/243], Loss: 2.3080\n",
      "Epoch [22/100], Step [220/243], Loss: 2.2780\n",
      "Epoch [22/100], Step [240/243], Loss: 2.4772\n",
      "\n",
      "train-loss: 4.0084, train-acc: 59.8044\n",
      "validation loss: 4.1151, validation acc: 56.3910\n",
      "\n",
      "Improvement-Detected, save-model\n",
      "Epoch 23\n",
      "\n",
      "Epoch [23/100], Step [0/243], Loss: 1.7273\n",
      "Epoch [23/100], Step [20/243], Loss: 2.5939\n",
      "Epoch [23/100], Step [40/243], Loss: 2.3028\n",
      "Epoch [23/100], Step [60/243], Loss: 2.0991\n",
      "Epoch [23/100], Step [80/243], Loss: 1.8495\n",
      "Epoch [23/100], Step [100/243], Loss: 2.4136\n",
      "Epoch [23/100], Step [120/243], Loss: 1.6502\n",
      "Epoch [23/100], Step [140/243], Loss: 2.1798\n",
      "Epoch [23/100], Step [160/243], Loss: 1.9509\n",
      "Epoch [23/100], Step [180/243], Loss: 1.8879\n",
      "Epoch [23/100], Step [200/243], Loss: 2.5857\n",
      "Epoch [23/100], Step [220/243], Loss: 2.9115\n",
      "Epoch [23/100], Step [240/243], Loss: 2.2280\n",
      "\n",
      "train-loss: 3.9318, train-acc: 61.3484\n",
      "validation loss: 4.0465, validation acc: 54.8872\n",
      "\n",
      "Improvement-Detected, save-model\n",
      "Epoch 24\n",
      "\n",
      "Epoch [24/100], Step [0/243], Loss: 1.9968\n",
      "Epoch [24/100], Step [20/243], Loss: 2.7785\n",
      "Epoch [24/100], Step [40/243], Loss: 2.0327\n",
      "Epoch [24/100], Step [60/243], Loss: 1.7804\n",
      "Epoch [24/100], Step [80/243], Loss: 2.3103\n",
      "Epoch [24/100], Step [100/243], Loss: 1.2030\n",
      "Epoch [24/100], Step [120/243], Loss: 1.7745\n",
      "Epoch [24/100], Step [140/243], Loss: 2.3158\n",
      "Epoch [24/100], Step [160/243], Loss: 2.2731\n",
      "Epoch [24/100], Step [180/243], Loss: 1.8278\n",
      "Epoch [24/100], Step [200/243], Loss: 2.6899\n",
      "Epoch [24/100], Step [220/243], Loss: 2.1705\n",
      "Epoch [24/100], Step [240/243], Loss: 2.1006\n",
      "\n",
      "train-loss: 3.8544, train-acc: 62.8410\n",
      "validation loss: 3.9788, validation acc: 59.3985\n",
      "\n",
      "Improvement-Detected, save-model\n",
      "Epoch 25\n",
      "\n",
      "Epoch [25/100], Step [0/243], Loss: 1.6484\n",
      "Epoch [25/100], Step [20/243], Loss: 1.9744\n",
      "Epoch [25/100], Step [40/243], Loss: 2.1361\n",
      "Epoch [25/100], Step [60/243], Loss: 1.7372\n",
      "Epoch [25/100], Step [80/243], Loss: 2.0848\n",
      "Epoch [25/100], Step [100/243], Loss: 1.3166\n",
      "Epoch [25/100], Step [120/243], Loss: 1.4028\n",
      "Epoch [25/100], Step [140/243], Loss: 1.3260\n",
      "Epoch [25/100], Step [160/243], Loss: 2.1015\n",
      "Epoch [25/100], Step [180/243], Loss: 1.4128\n",
      "Epoch [25/100], Step [200/243], Loss: 1.7917\n",
      "Epoch [25/100], Step [220/243], Loss: 1.3193\n",
      "Epoch [25/100], Step [240/243], Loss: 2.1897\n",
      "\n",
      "train-loss: 3.7774, train-acc: 63.3556\n",
      "validation loss: 3.9055, validation acc: 62.4060\n",
      "\n",
      "Improvement-Detected, save-model\n",
      "Epoch 26\n",
      "\n",
      "Epoch [26/100], Step [0/243], Loss: 1.4502\n",
      "Epoch [26/100], Step [20/243], Loss: 1.8048\n",
      "Epoch [26/100], Step [40/243], Loss: 2.4701\n",
      "Epoch [26/100], Step [60/243], Loss: 2.0400\n",
      "Epoch [26/100], Step [80/243], Loss: 1.1888\n",
      "Epoch [26/100], Step [100/243], Loss: 1.8393\n",
      "Epoch [26/100], Step [120/243], Loss: 2.3096\n",
      "Epoch [26/100], Step [140/243], Loss: 2.4759\n",
      "Epoch [26/100], Step [160/243], Loss: 2.1656\n",
      "Epoch [26/100], Step [180/243], Loss: 2.6155\n",
      "Epoch [26/100], Step [200/243], Loss: 1.2839\n",
      "Epoch [26/100], Step [220/243], Loss: 1.3828\n",
      "Epoch [26/100], Step [240/243], Loss: 1.5412\n",
      "\n",
      "train-loss: 3.7015, train-acc: 62.6866\n",
      "validation loss: 3.8369, validation acc: 63.1579\n",
      "\n",
      "Improvement-Detected, save-model\n",
      "Epoch 27\n",
      "\n",
      "Epoch [27/100], Step [0/243], Loss: 2.2150\n",
      "Epoch [27/100], Step [20/243], Loss: 2.1043\n",
      "Epoch [27/100], Step [40/243], Loss: 1.1212\n",
      "Epoch [27/100], Step [60/243], Loss: 1.4258\n",
      "Epoch [27/100], Step [80/243], Loss: 2.7877\n",
      "Epoch [27/100], Step [100/243], Loss: 1.2863\n",
      "Epoch [27/100], Step [120/243], Loss: 2.0909\n",
      "Epoch [27/100], Step [140/243], Loss: 2.8947\n",
      "Epoch [27/100], Step [160/243], Loss: 2.9034\n",
      "Epoch [27/100], Step [180/243], Loss: 0.8544\n",
      "Epoch [27/100], Step [200/243], Loss: 1.7455\n",
      "Epoch [27/100], Step [220/243], Loss: 2.2575\n",
      "Epoch [27/100], Step [240/243], Loss: 1.9407\n",
      "\n",
      "train-loss: 3.6258, train-acc: 65.2599\n",
      "validation loss: 3.7692, validation acc: 62.4060\n",
      "\n",
      "Improvement-Detected, save-model\n",
      "Epoch 28\n",
      "\n",
      "Epoch [28/100], Step [0/243], Loss: 0.9083\n",
      "Epoch [28/100], Step [20/243], Loss: 2.7791\n",
      "Epoch [28/100], Step [40/243], Loss: 0.7000\n",
      "Epoch [28/100], Step [60/243], Loss: 1.7345\n",
      "Epoch [28/100], Step [80/243], Loss: 1.3220\n",
      "Epoch [28/100], Step [100/243], Loss: 1.7460\n",
      "Epoch [28/100], Step [120/243], Loss: 1.8133\n",
      "Epoch [28/100], Step [140/243], Loss: 1.1729\n",
      "Epoch [28/100], Step [160/243], Loss: 1.6486\n",
      "Epoch [28/100], Step [180/243], Loss: 2.6268\n",
      "Epoch [28/100], Step [200/243], Loss: 2.9072\n",
      "Epoch [28/100], Step [220/243], Loss: 1.1556\n",
      "Epoch [28/100], Step [240/243], Loss: 1.5986\n",
      "\n",
      "train-loss: 3.5514, train-acc: 66.8039\n",
      "validation loss: 3.7018, validation acc: 63.1579\n",
      "\n",
      "Improvement-Detected, save-model\n",
      "Epoch 29\n",
      "\n",
      "Epoch [29/100], Step [0/243], Loss: 2.2832\n",
      "Epoch [29/100], Step [20/243], Loss: 1.8791\n",
      "Epoch [29/100], Step [40/243], Loss: 1.2007\n",
      "Epoch [29/100], Step [60/243], Loss: 2.5064\n",
      "Epoch [29/100], Step [80/243], Loss: 1.1243\n",
      "Epoch [29/100], Step [100/243], Loss: 1.9985\n",
      "Epoch [29/100], Step [120/243], Loss: 1.4933\n",
      "Epoch [29/100], Step [140/243], Loss: 0.9742\n",
      "Epoch [29/100], Step [160/243], Loss: 1.2084\n",
      "Epoch [29/100], Step [180/243], Loss: 1.2585\n",
      "Epoch [29/100], Step [200/243], Loss: 1.8561\n",
      "Epoch [29/100], Step [220/243], Loss: 1.1181\n",
      "Epoch [29/100], Step [240/243], Loss: 3.1474\n",
      "\n",
      "train-loss: 3.4804, train-acc: 65.5172\n",
      "validation loss: 3.6365, validation acc: 64.6617\n",
      "\n",
      "Improvement-Detected, save-model\n",
      "Epoch 30\n",
      "\n",
      "Epoch [30/100], Step [0/243], Loss: 1.7003\n",
      "Epoch [30/100], Step [20/243], Loss: 1.2996\n",
      "Epoch [30/100], Step [40/243], Loss: 1.3630\n",
      "Epoch [30/100], Step [60/243], Loss: 1.7170\n",
      "Epoch [30/100], Step [80/243], Loss: 1.6941\n",
      "Epoch [30/100], Step [100/243], Loss: 1.2836\n",
      "Epoch [30/100], Step [120/243], Loss: 1.4243\n",
      "Epoch [30/100], Step [140/243], Loss: 0.9617\n",
      "Epoch [30/100], Step [160/243], Loss: 1.8602\n",
      "Epoch [30/100], Step [180/243], Loss: 1.4297\n",
      "Epoch [30/100], Step [200/243], Loss: 2.7297\n",
      "Epoch [30/100], Step [220/243], Loss: 0.8016\n",
      "Epoch [30/100], Step [240/243], Loss: 1.6299\n",
      "\n",
      "train-loss: 3.4117, train-acc: 66.5466\n",
      "validation loss: 3.5705, validation acc: 67.6692\n",
      "\n",
      "Improvement-Detected, save-model\n",
      "Epoch 31\n",
      "\n",
      "Epoch [31/100], Step [0/243], Loss: 1.0598\n",
      "Epoch [31/100], Step [20/243], Loss: 1.8256\n",
      "Epoch [31/100], Step [40/243], Loss: 1.9613\n",
      "Epoch [31/100], Step [60/243], Loss: 1.3608\n",
      "Epoch [31/100], Step [80/243], Loss: 1.0872\n",
      "Epoch [31/100], Step [100/243], Loss: 1.2031\n",
      "Epoch [31/100], Step [120/243], Loss: 1.9465\n",
      "Epoch [31/100], Step [140/243], Loss: 1.6359\n",
      "Epoch [31/100], Step [160/243], Loss: 0.4405\n",
      "Epoch [31/100], Step [180/243], Loss: 1.6115\n",
      "Epoch [31/100], Step [200/243], Loss: 1.3506\n",
      "Epoch [31/100], Step [220/243], Loss: 2.0229\n",
      "Epoch [31/100], Step [240/243], Loss: 0.8132\n",
      "\n",
      "train-loss: 3.3436, train-acc: 68.1935\n",
      "validation loss: 3.5071, validation acc: 64.6617\n",
      "\n",
      "Improvement-Detected, save-model\n",
      "Epoch 32\n",
      "\n",
      "Epoch [32/100], Step [0/243], Loss: 1.0603\n",
      "Epoch [32/100], Step [20/243], Loss: 0.9103\n",
      "Epoch [32/100], Step [40/243], Loss: 1.1245\n",
      "Epoch [32/100], Step [60/243], Loss: 0.4452\n",
      "Epoch [32/100], Step [80/243], Loss: 1.0477\n",
      "Epoch [32/100], Step [100/243], Loss: 1.2965\n",
      "Epoch [32/100], Step [120/243], Loss: 1.8754\n",
      "Epoch [32/100], Step [140/243], Loss: 0.6378\n",
      "Epoch [32/100], Step [160/243], Loss: 1.0271\n",
      "Epoch [32/100], Step [180/243], Loss: 1.4988\n",
      "Epoch [32/100], Step [200/243], Loss: 2.2123\n",
      "Epoch [32/100], Step [220/243], Loss: 1.1489\n",
      "Epoch [32/100], Step [240/243], Loss: 1.0548\n",
      "\n",
      "train-loss: 3.2790, train-acc: 67.6274\n",
      "validation loss: 3.4461, validation acc: 65.4135\n",
      "\n",
      "Improvement-Detected, save-model\n",
      "Epoch 33\n",
      "\n",
      "Epoch [33/100], Step [0/243], Loss: 0.7386\n",
      "Epoch [33/100], Step [20/243], Loss: 0.5689\n",
      "Epoch [33/100], Step [40/243], Loss: 1.0072\n",
      "Epoch [33/100], Step [60/243], Loss: 0.5943\n",
      "Epoch [33/100], Step [80/243], Loss: 0.6423\n",
      "Epoch [33/100], Step [100/243], Loss: 1.6345\n",
      "Epoch [33/100], Step [120/243], Loss: 2.1338\n",
      "Epoch [33/100], Step [140/243], Loss: 0.7636\n",
      "Epoch [33/100], Step [160/243], Loss: 0.7594\n",
      "Epoch [33/100], Step [180/243], Loss: 1.5680\n",
      "Epoch [33/100], Step [200/243], Loss: 0.9799\n",
      "Epoch [33/100], Step [220/243], Loss: 1.5371\n",
      "Epoch [33/100], Step [240/243], Loss: 1.6063\n",
      "\n",
      "train-loss: 3.2156, train-acc: 69.9949\n",
      "validation loss: 3.3843, validation acc: 66.1654\n",
      "\n",
      "Improvement-Detected, save-model\n",
      "Epoch 34\n",
      "\n",
      "Epoch [34/100], Step [0/243], Loss: 1.0331\n",
      "Epoch [34/100], Step [20/243], Loss: 3.0378\n",
      "Epoch [34/100], Step [40/243], Loss: 1.0735\n",
      "Epoch [34/100], Step [60/243], Loss: 1.9920\n",
      "Epoch [34/100], Step [80/243], Loss: 1.1480\n",
      "Epoch [34/100], Step [100/243], Loss: 0.8942\n",
      "Epoch [34/100], Step [120/243], Loss: 1.2321\n",
      "Epoch [34/100], Step [140/243], Loss: 0.8575\n",
      "Epoch [34/100], Step [160/243], Loss: 1.2362\n",
      "Epoch [34/100], Step [180/243], Loss: 1.6618\n",
      "Epoch [34/100], Step [200/243], Loss: 0.7714\n",
      "Epoch [34/100], Step [220/243], Loss: 1.9478\n",
      "Epoch [34/100], Step [240/243], Loss: 2.0009\n",
      "\n",
      "train-loss: 3.1550, train-acc: 69.5317\n",
      "validation loss: 3.3253, validation acc: 66.9173\n",
      "\n",
      "Improvement-Detected, save-model\n",
      "Epoch 35\n",
      "\n",
      "Epoch [35/100], Step [0/243], Loss: 1.5067\n",
      "Epoch [35/100], Step [20/243], Loss: 0.8242\n",
      "Epoch [35/100], Step [40/243], Loss: 1.4438\n",
      "Epoch [35/100], Step [60/243], Loss: 0.8879\n",
      "Epoch [35/100], Step [80/243], Loss: 0.7592\n",
      "Epoch [35/100], Step [100/243], Loss: 0.7145\n",
      "Epoch [35/100], Step [120/243], Loss: 0.7853\n",
      "Epoch [35/100], Step [140/243], Loss: 0.6853\n",
      "Epoch [35/100], Step [160/243], Loss: 0.5667\n",
      "Epoch [35/100], Step [180/243], Loss: 0.8772\n",
      "Epoch [35/100], Step [200/243], Loss: 1.1318\n",
      "Epoch [35/100], Step [220/243], Loss: 1.4320\n",
      "Epoch [35/100], Step [240/243], Loss: 0.3816\n",
      "\n",
      "train-loss: 3.0954, train-acc: 71.3330\n",
      "validation loss: 3.2699, validation acc: 68.4211\n",
      "\n",
      "Epoch 36\n",
      "\n",
      "Epoch [36/100], Step [0/243], Loss: 1.3302\n",
      "Epoch [36/100], Step [20/243], Loss: 1.3842\n",
      "Epoch [36/100], Step [40/243], Loss: 1.5784\n",
      "Epoch [36/100], Step [60/243], Loss: 0.8292\n",
      "Epoch [36/100], Step [80/243], Loss: 0.9859\n",
      "Epoch [36/100], Step [100/243], Loss: 0.4719\n",
      "Epoch [36/100], Step [120/243], Loss: 0.7787\n",
      "Epoch [36/100], Step [140/243], Loss: 0.7213\n",
      "Epoch [36/100], Step [160/243], Loss: 2.4707\n",
      "Epoch [36/100], Step [180/243], Loss: 0.5249\n",
      "Epoch [36/100], Step [200/243], Loss: 1.3423\n",
      "Epoch [36/100], Step [220/243], Loss: 1.3687\n",
      "Epoch [36/100], Step [240/243], Loss: 1.0611\n",
      "\n",
      "train-loss: 3.0391, train-acc: 71.4359\n",
      "validation loss: 3.2144, validation acc: 66.9173\n",
      "\n",
      "Improvement-Detected, save-model\n",
      "Epoch 37\n",
      "\n",
      "Epoch [37/100], Step [0/243], Loss: 1.0138\n",
      "Epoch [37/100], Step [20/243], Loss: 0.8696\n",
      "Epoch [37/100], Step [40/243], Loss: 1.0764\n",
      "Epoch [37/100], Step [60/243], Loss: 1.4092\n",
      "Epoch [37/100], Step [80/243], Loss: 0.9056\n",
      "Epoch [37/100], Step [100/243], Loss: 1.4610\n",
      "Epoch [37/100], Step [120/243], Loss: 1.2896\n",
      "Epoch [37/100], Step [140/243], Loss: 0.5391\n",
      "Epoch [37/100], Step [160/243], Loss: 1.0904\n",
      "Epoch [37/100], Step [180/243], Loss: 1.1128\n",
      "Epoch [37/100], Step [200/243], Loss: 1.3571\n",
      "Epoch [37/100], Step [220/243], Loss: 0.6781\n",
      "Epoch [37/100], Step [240/243], Loss: 0.6502\n",
      "\n",
      "train-loss: 2.9845, train-acc: 71.7962\n",
      "validation loss: 3.1614, validation acc: 66.1654\n",
      "\n",
      "Improvement-Detected, save-model\n",
      "Epoch 38\n",
      "\n",
      "Epoch [38/100], Step [0/243], Loss: 0.6183\n",
      "Epoch [38/100], Step [20/243], Loss: 1.1815\n",
      "Epoch [38/100], Step [40/243], Loss: 1.1346\n",
      "Epoch [38/100], Step [60/243], Loss: 1.0104\n",
      "Epoch [38/100], Step [80/243], Loss: 1.1959\n",
      "Epoch [38/100], Step [100/243], Loss: 1.0308\n",
      "Epoch [38/100], Step [120/243], Loss: 0.9263\n",
      "Epoch [38/100], Step [140/243], Loss: 0.9638\n",
      "Epoch [38/100], Step [160/243], Loss: 0.5374\n",
      "Epoch [38/100], Step [180/243], Loss: 0.4026\n",
      "Epoch [38/100], Step [200/243], Loss: 0.4301\n",
      "Epoch [38/100], Step [220/243], Loss: 1.7315\n",
      "Epoch [38/100], Step [240/243], Loss: 0.5354\n",
      "\n",
      "train-loss: 2.9317, train-acc: 73.2887\n",
      "validation loss: 3.1102, validation acc: 66.9173\n",
      "\n",
      "Improvement-Detected, save-model\n",
      "Epoch 39\n",
      "\n",
      "Epoch [39/100], Step [0/243], Loss: 0.6547\n",
      "Epoch [39/100], Step [20/243], Loss: 1.3588\n",
      "Epoch [39/100], Step [40/243], Loss: 0.3932\n",
      "Epoch [39/100], Step [60/243], Loss: 0.5519\n",
      "Epoch [39/100], Step [80/243], Loss: 1.3684\n",
      "Epoch [39/100], Step [100/243], Loss: 0.7673\n",
      "Epoch [39/100], Step [120/243], Loss: 0.9372\n",
      "Epoch [39/100], Step [140/243], Loss: 1.1383\n",
      "Epoch [39/100], Step [160/243], Loss: 0.3680\n",
      "Epoch [39/100], Step [180/243], Loss: 1.3506\n",
      "Epoch [39/100], Step [200/243], Loss: 0.8154\n",
      "Epoch [39/100], Step [220/243], Loss: 0.8076\n",
      "Epoch [39/100], Step [240/243], Loss: 1.4231\n",
      "\n",
      "train-loss: 2.8806, train-acc: 73.9578\n",
      "validation loss: 3.0597, validation acc: 68.4211\n",
      "\n",
      "Improvement-Detected, save-model\n",
      "Epoch 40\n",
      "\n",
      "Epoch [40/100], Step [0/243], Loss: 1.6645\n",
      "Epoch [40/100], Step [20/243], Loss: 0.6711\n",
      "Epoch [40/100], Step [40/243], Loss: 1.5739\n",
      "Epoch [40/100], Step [60/243], Loss: 2.3468\n",
      "Epoch [40/100], Step [80/243], Loss: 0.6992\n",
      "Epoch [40/100], Step [100/243], Loss: 0.1762\n",
      "Epoch [40/100], Step [120/243], Loss: 1.0691\n",
      "Epoch [40/100], Step [140/243], Loss: 1.1419\n",
      "Epoch [40/100], Step [160/243], Loss: 1.8031\n",
      "Epoch [40/100], Step [180/243], Loss: 0.9956\n",
      "Epoch [40/100], Step [200/243], Loss: 0.4026\n",
      "Epoch [40/100], Step [220/243], Loss: 0.9246\n",
      "Epoch [40/100], Step [240/243], Loss: 2.3682\n",
      "\n",
      "train-loss: 2.8308, train-acc: 74.9871\n",
      "validation loss: 3.0117, validation acc: 68.4211\n",
      "\n",
      "Epoch 41\n",
      "\n",
      "Epoch [41/100], Step [0/243], Loss: 0.8632\n",
      "Epoch [41/100], Step [20/243], Loss: 1.1269\n",
      "Epoch [41/100], Step [40/243], Loss: 0.9316\n",
      "Epoch [41/100], Step [60/243], Loss: 0.5897\n",
      "Epoch [41/100], Step [80/243], Loss: 1.1212\n",
      "Epoch [41/100], Step [100/243], Loss: 1.3967\n",
      "Epoch [41/100], Step [120/243], Loss: 1.0862\n",
      "Epoch [41/100], Step [140/243], Loss: 1.2508\n",
      "Epoch [41/100], Step [160/243], Loss: 1.0425\n",
      "Epoch [41/100], Step [180/243], Loss: 0.8619\n",
      "Epoch [41/100], Step [200/243], Loss: 1.1664\n",
      "Epoch [41/100], Step [220/243], Loss: 0.6047\n",
      "Epoch [41/100], Step [240/243], Loss: 0.5406\n",
      "\n",
      "train-loss: 2.7826, train-acc: 76.1709\n",
      "validation loss: 2.9648, validation acc: 68.4211\n",
      "\n",
      "Improvement-Detected, save-model\n",
      "Epoch 42\n",
      "\n",
      "Epoch [42/100], Step [0/243], Loss: 0.8542\n",
      "Epoch [42/100], Step [20/243], Loss: 0.7667\n",
      "Epoch [42/100], Step [40/243], Loss: 0.6860\n",
      "Epoch [42/100], Step [60/243], Loss: 1.3328\n",
      "Epoch [42/100], Step [80/243], Loss: 0.8616\n",
      "Epoch [42/100], Step [100/243], Loss: 0.8965\n",
      "Epoch [42/100], Step [120/243], Loss: 0.8793\n",
      "Epoch [42/100], Step [140/243], Loss: 0.7905\n",
      "Epoch [42/100], Step [160/243], Loss: 0.3853\n",
      "Epoch [42/100], Step [180/243], Loss: 1.7803\n",
      "Epoch [42/100], Step [200/243], Loss: 0.4872\n",
      "Epoch [42/100], Step [220/243], Loss: 0.6882\n",
      "Epoch [42/100], Step [240/243], Loss: 1.0180\n",
      "\n",
      "train-loss: 2.7365, train-acc: 75.8621\n",
      "validation loss: 2.9202, validation acc: 68.4211\n",
      "\n",
      "Epoch 43\n",
      "\n",
      "Epoch [43/100], Step [0/243], Loss: 2.3252\n",
      "Epoch [43/100], Step [20/243], Loss: 1.0776\n",
      "Epoch [43/100], Step [40/243], Loss: 1.0532\n",
      "Epoch [43/100], Step [60/243], Loss: 0.9912\n",
      "Epoch [43/100], Step [80/243], Loss: 0.6009\n",
      "Epoch [43/100], Step [100/243], Loss: 0.8680\n",
      "Epoch [43/100], Step [120/243], Loss: 0.9100\n",
      "Epoch [43/100], Step [140/243], Loss: 0.2120\n",
      "Epoch [43/100], Step [160/243], Loss: 1.9499\n",
      "Epoch [43/100], Step [180/243], Loss: 0.8714\n",
      "Epoch [43/100], Step [200/243], Loss: 1.2296\n",
      "Epoch [43/100], Step [220/243], Loss: 0.9422\n",
      "Epoch [43/100], Step [240/243], Loss: 1.2610\n",
      "\n",
      "train-loss: 2.6920, train-acc: 76.5311\n",
      "validation loss: 2.8763, validation acc: 70.6767\n",
      "\n",
      "Improvement-Detected, save-model\n",
      "Epoch 44\n",
      "\n",
      "Epoch [44/100], Step [0/243], Loss: 1.3558\n",
      "Epoch [44/100], Step [20/243], Loss: 0.5885\n",
      "Epoch [44/100], Step [40/243], Loss: 1.0651\n",
      "Epoch [44/100], Step [60/243], Loss: 0.7290\n",
      "Epoch [44/100], Step [80/243], Loss: 0.3563\n",
      "Epoch [44/100], Step [100/243], Loss: 0.5370\n",
      "Epoch [44/100], Step [120/243], Loss: 0.3262\n",
      "Epoch [44/100], Step [140/243], Loss: 0.4636\n",
      "Epoch [44/100], Step [160/243], Loss: 1.5183\n",
      "Epoch [44/100], Step [180/243], Loss: 0.4564\n",
      "Epoch [44/100], Step [200/243], Loss: 0.8722\n",
      "Epoch [44/100], Step [220/243], Loss: 1.1117\n",
      "Epoch [44/100], Step [240/243], Loss: 0.8333\n",
      "\n",
      "train-loss: 2.6486, train-acc: 77.4575\n",
      "validation loss: 2.8335, validation acc: 74.4361\n",
      "\n",
      "Improvement-Detected, save-model\n",
      "Epoch 45\n",
      "\n",
      "Epoch [45/100], Step [0/243], Loss: 0.8919\n",
      "Epoch [45/100], Step [20/243], Loss: 1.1346\n",
      "Epoch [45/100], Step [40/243], Loss: 0.9158\n",
      "Epoch [45/100], Step [60/243], Loss: 0.4420\n",
      "Epoch [45/100], Step [80/243], Loss: 1.3874\n",
      "Epoch [45/100], Step [100/243], Loss: 0.3390\n",
      "Epoch [45/100], Step [120/243], Loss: 0.3157\n",
      "Epoch [45/100], Step [140/243], Loss: 0.2278\n",
      "Epoch [45/100], Step [160/243], Loss: 0.3867\n",
      "Epoch [45/100], Step [180/243], Loss: 0.3204\n",
      "Epoch [45/100], Step [200/243], Loss: 0.4868\n",
      "Epoch [45/100], Step [220/243], Loss: 0.8734\n",
      "Epoch [45/100], Step [240/243], Loss: 0.6833\n",
      "\n",
      "train-loss: 2.6068, train-acc: 77.7663\n",
      "validation loss: 2.7922, validation acc: 73.6842\n",
      "\n",
      "Improvement-Detected, save-model\n",
      "Epoch 46\n",
      "\n",
      "Epoch [46/100], Step [0/243], Loss: 1.0762\n",
      "Epoch [46/100], Step [20/243], Loss: 1.4765\n",
      "Epoch [46/100], Step [40/243], Loss: 0.2085\n",
      "Epoch [46/100], Step [60/243], Loss: 0.3482\n",
      "Epoch [46/100], Step [80/243], Loss: 0.2498\n",
      "Epoch [46/100], Step [100/243], Loss: 0.5927\n",
      "Epoch [46/100], Step [120/243], Loss: 0.4794\n",
      "Epoch [46/100], Step [140/243], Loss: 0.3319\n",
      "Epoch [46/100], Step [160/243], Loss: 1.0705\n",
      "Epoch [46/100], Step [180/243], Loss: 0.6566\n",
      "Epoch [46/100], Step [200/243], Loss: 0.6024\n",
      "Epoch [46/100], Step [220/243], Loss: 0.7289\n",
      "Epoch [46/100], Step [240/243], Loss: 0.7512\n",
      "\n",
      "train-loss: 2.5659, train-acc: 79.4133\n",
      "validation loss: 2.7527, validation acc: 72.9323\n",
      "\n",
      "Epoch 47\n",
      "\n",
      "Epoch [47/100], Step [0/243], Loss: 1.4815\n",
      "Epoch [47/100], Step [20/243], Loss: 1.3918\n",
      "Epoch [47/100], Step [40/243], Loss: 0.3094\n",
      "Epoch [47/100], Step [60/243], Loss: 0.3912\n",
      "Epoch [47/100], Step [80/243], Loss: 1.3312\n",
      "Epoch [47/100], Step [100/243], Loss: 1.5696\n",
      "Epoch [47/100], Step [120/243], Loss: 0.9769\n",
      "Epoch [47/100], Step [140/243], Loss: 0.5473\n",
      "Epoch [47/100], Step [160/243], Loss: 0.3045\n",
      "Epoch [47/100], Step [180/243], Loss: 0.9108\n",
      "Epoch [47/100], Step [200/243], Loss: 0.6263\n",
      "Epoch [47/100], Step [220/243], Loss: 0.2247\n",
      "Epoch [47/100], Step [240/243], Loss: 0.2539\n",
      "\n",
      "train-loss: 2.5257, train-acc: 82.1925\n",
      "validation loss: 2.7144, validation acc: 74.4361\n",
      "\n",
      "Improvement-Detected, save-model\n",
      "Epoch 48\n",
      "\n",
      "Epoch [48/100], Step [0/243], Loss: 0.7512\n",
      "Epoch [48/100], Step [20/243], Loss: 0.1163\n",
      "Epoch [48/100], Step [40/243], Loss: 1.1969\n",
      "Epoch [48/100], Step [60/243], Loss: 0.6792\n",
      "Epoch [48/100], Step [80/243], Loss: 0.3574\n",
      "Epoch [48/100], Step [100/243], Loss: 1.0653\n",
      "Epoch [48/100], Step [120/243], Loss: 0.2274\n",
      "Epoch [48/100], Step [140/243], Loss: 0.7904\n",
      "Epoch [48/100], Step [160/243], Loss: 1.0969\n",
      "Epoch [48/100], Step [180/243], Loss: 1.0358\n",
      "Epoch [48/100], Step [200/243], Loss: 0.6707\n",
      "Epoch [48/100], Step [220/243], Loss: 0.4427\n",
      "Epoch [48/100], Step [240/243], Loss: 1.2725\n",
      "\n",
      "train-loss: 2.4862, train-acc: 81.5234\n",
      "validation loss: 2.6771, validation acc: 74.4361\n",
      "\n",
      "Improvement-Detected, save-model\n",
      "Epoch 49\n",
      "\n",
      "Epoch [49/100], Step [0/243], Loss: 0.5732\n",
      "Epoch [49/100], Step [20/243], Loss: 0.6457\n",
      "Epoch [49/100], Step [40/243], Loss: 1.4210\n",
      "Epoch [49/100], Step [60/243], Loss: 1.2550\n",
      "Epoch [49/100], Step [80/243], Loss: 0.2054\n",
      "Epoch [49/100], Step [100/243], Loss: 0.0777\n",
      "Epoch [49/100], Step [120/243], Loss: 0.6693\n",
      "Epoch [49/100], Step [140/243], Loss: 0.3841\n",
      "Epoch [49/100], Step [160/243], Loss: 0.3206\n",
      "Epoch [49/100], Step [180/243], Loss: 1.1308\n",
      "Epoch [49/100], Step [200/243], Loss: 0.5132\n",
      "Epoch [49/100], Step [220/243], Loss: 0.3045\n",
      "Epoch [49/100], Step [240/243], Loss: 0.4771\n",
      "\n",
      "train-loss: 2.4490, train-acc: 80.8543\n",
      "validation loss: 2.6414, validation acc: 74.4361\n",
      "\n",
      "Epoch 50\n",
      "\n",
      "Epoch [50/100], Step [0/243], Loss: 0.3453\n",
      "Epoch [50/100], Step [20/243], Loss: 0.7563\n",
      "Epoch [50/100], Step [40/243], Loss: 0.3059\n",
      "Epoch [50/100], Step [60/243], Loss: 0.4125\n",
      "Epoch [50/100], Step [80/243], Loss: 0.4852\n",
      "Epoch [50/100], Step [100/243], Loss: 0.4253\n",
      "Epoch [50/100], Step [120/243], Loss: 0.5102\n",
      "Epoch [50/100], Step [140/243], Loss: 1.2648\n",
      "Epoch [50/100], Step [160/243], Loss: 0.2838\n",
      "Epoch [50/100], Step [180/243], Loss: 0.6952\n",
      "Epoch [50/100], Step [200/243], Loss: 0.5809\n",
      "Epoch [50/100], Step [220/243], Loss: 0.4092\n",
      "Epoch [50/100], Step [240/243], Loss: 0.5328\n",
      "\n",
      "train-loss: 2.4124, train-acc: 82.0896\n",
      "validation loss: 2.6067, validation acc: 74.4361\n",
      "\n",
      "Improvement-Detected, save-model\n",
      "Epoch 51\n",
      "\n",
      "Epoch [51/100], Step [0/243], Loss: 0.7000\n",
      "Epoch [51/100], Step [20/243], Loss: 0.8827\n",
      "Epoch [51/100], Step [40/243], Loss: 0.2767\n",
      "Epoch [51/100], Step [60/243], Loss: 1.3086\n",
      "Epoch [51/100], Step [80/243], Loss: 0.3755\n",
      "Epoch [51/100], Step [100/243], Loss: 0.3439\n",
      "Epoch [51/100], Step [120/243], Loss: 0.4563\n",
      "Epoch [51/100], Step [140/243], Loss: 0.8471\n",
      "Epoch [51/100], Step [160/243], Loss: 0.8965\n",
      "Epoch [51/100], Step [180/243], Loss: 0.4692\n",
      "Epoch [51/100], Step [200/243], Loss: 0.6288\n",
      "Epoch [51/100], Step [220/243], Loss: 0.5847\n",
      "Epoch [51/100], Step [240/243], Loss: 0.6351\n",
      "\n",
      "train-loss: 2.3766, train-acc: 83.4792\n",
      "validation loss: 2.5759, validation acc: 71.4286\n",
      "\n",
      "Epoch 52\n",
      "\n",
      "Epoch [52/100], Step [0/243], Loss: 0.2758\n",
      "Epoch [52/100], Step [20/243], Loss: 0.7632\n",
      "Epoch [52/100], Step [40/243], Loss: 0.3778\n",
      "Epoch [52/100], Step [60/243], Loss: 0.5005\n",
      "Epoch [52/100], Step [80/243], Loss: 0.7752\n",
      "Epoch [52/100], Step [100/243], Loss: 0.7548\n",
      "Epoch [52/100], Step [120/243], Loss: 1.0494\n",
      "Epoch [52/100], Step [140/243], Loss: 0.5567\n",
      "Epoch [52/100], Step [160/243], Loss: 0.4106\n",
      "Epoch [52/100], Step [180/243], Loss: 0.6532\n",
      "Epoch [52/100], Step [200/243], Loss: 0.8849\n",
      "Epoch [52/100], Step [220/243], Loss: 0.4397\n",
      "Epoch [52/100], Step [240/243], Loss: 0.3690\n",
      "\n",
      "train-loss: 2.3422, train-acc: 83.6336\n",
      "validation loss: 2.5439, validation acc: 73.6842\n",
      "\n",
      "Epoch 53\n",
      "\n",
      "Epoch [53/100], Step [0/243], Loss: 0.7641\n",
      "Epoch [53/100], Step [20/243], Loss: 0.6977\n",
      "Epoch [53/100], Step [40/243], Loss: 0.3112\n",
      "Epoch [53/100], Step [60/243], Loss: 0.6128\n",
      "Epoch [53/100], Step [80/243], Loss: 0.5114\n",
      "Epoch [53/100], Step [100/243], Loss: 0.7217\n",
      "Epoch [53/100], Step [120/243], Loss: 0.2468\n",
      "Epoch [53/100], Step [140/243], Loss: 0.9488\n",
      "Epoch [53/100], Step [160/243], Loss: 0.4847\n",
      "Epoch [53/100], Step [180/243], Loss: 0.4633\n",
      "Epoch [53/100], Step [200/243], Loss: 0.4976\n",
      "Epoch [53/100], Step [220/243], Loss: 0.5481\n",
      "Epoch [53/100], Step [240/243], Loss: 0.2659\n",
      "\n",
      "train-loss: 2.3082, train-acc: 85.2805\n",
      "validation loss: 2.5128, validation acc: 72.9323\n",
      "\n",
      "Improvement-Detected, save-model\n",
      "Epoch 54\n",
      "\n",
      "Epoch [54/100], Step [0/243], Loss: 0.3254\n",
      "Epoch [54/100], Step [20/243], Loss: 0.1953\n",
      "Epoch [54/100], Step [40/243], Loss: 0.4298\n",
      "Epoch [54/100], Step [60/243], Loss: 0.6767\n",
      "Epoch [54/100], Step [80/243], Loss: 0.6404\n",
      "Epoch [54/100], Step [100/243], Loss: 0.7075\n",
      "Epoch [54/100], Step [120/243], Loss: 0.6983\n",
      "Epoch [54/100], Step [140/243], Loss: 0.9271\n",
      "Epoch [54/100], Step [160/243], Loss: 0.8659\n",
      "Epoch [54/100], Step [180/243], Loss: 0.5720\n",
      "Epoch [54/100], Step [200/243], Loss: 0.2372\n",
      "Epoch [54/100], Step [220/243], Loss: 0.5772\n",
      "Epoch [54/100], Step [240/243], Loss: 0.4277\n",
      "\n",
      "train-loss: 2.2752, train-acc: 85.3834\n",
      "validation loss: 2.4823, validation acc: 74.4361\n",
      "\n",
      "Improvement-Detected, save-model\n",
      "Epoch 55\n",
      "\n",
      "Epoch [55/100], Step [0/243], Loss: 0.4096\n",
      "Epoch [55/100], Step [20/243], Loss: 0.1298\n",
      "Epoch [55/100], Step [40/243], Loss: 1.4535\n",
      "Epoch [55/100], Step [60/243], Loss: 0.7666\n",
      "Epoch [55/100], Step [80/243], Loss: 0.5761\n",
      "Epoch [55/100], Step [100/243], Loss: 0.6803\n",
      "Epoch [55/100], Step [120/243], Loss: 0.2874\n",
      "Epoch [55/100], Step [140/243], Loss: 0.5562\n",
      "Epoch [55/100], Step [160/243], Loss: 0.6072\n",
      "Epoch [55/100], Step [180/243], Loss: 0.4602\n",
      "Epoch [55/100], Step [200/243], Loss: 0.3688\n",
      "Epoch [55/100], Step [220/243], Loss: 0.7525\n",
      "Epoch [55/100], Step [240/243], Loss: 0.8889\n",
      "\n",
      "train-loss: 2.2431, train-acc: 85.3834\n",
      "validation loss: 2.4540, validation acc: 73.6842\n",
      "\n",
      "Epoch 56\n",
      "\n",
      "Epoch [56/100], Step [0/243], Loss: 0.2648\n",
      "Epoch [56/100], Step [20/243], Loss: 0.3505\n",
      "Epoch [56/100], Step [40/243], Loss: 0.4063\n",
      "Epoch [56/100], Step [60/243], Loss: 0.4777\n",
      "Epoch [56/100], Step [80/243], Loss: 0.1989\n",
      "Epoch [56/100], Step [100/243], Loss: 0.7534\n",
      "Epoch [56/100], Step [120/243], Loss: 0.4908\n",
      "Epoch [56/100], Step [140/243], Loss: 0.3457\n",
      "Epoch [56/100], Step [160/243], Loss: 0.8864\n",
      "Epoch [56/100], Step [180/243], Loss: 0.3125\n",
      "Epoch [56/100], Step [200/243], Loss: 0.4185\n",
      "Epoch [56/100], Step [220/243], Loss: 0.2228\n",
      "Epoch [56/100], Step [240/243], Loss: 0.3180\n",
      "\n",
      "train-loss: 2.2120, train-acc: 85.9496\n",
      "validation loss: 2.4261, validation acc: 74.4361\n",
      "\n",
      "Epoch 57\n",
      "\n",
      "Epoch [57/100], Step [0/243], Loss: 0.3613\n",
      "Epoch [57/100], Step [20/243], Loss: 0.1809\n",
      "Epoch [57/100], Step [40/243], Loss: 0.1533\n",
      "Epoch [57/100], Step [60/243], Loss: 0.5454\n",
      "Epoch [57/100], Step [80/243], Loss: 0.5352\n",
      "Epoch [57/100], Step [100/243], Loss: 0.3240\n",
      "Epoch [57/100], Step [120/243], Loss: 0.5206\n",
      "Epoch [57/100], Step [140/243], Loss: 0.6085\n",
      "Epoch [57/100], Step [160/243], Loss: 0.2792\n",
      "Epoch [57/100], Step [180/243], Loss: 1.1881\n",
      "Epoch [57/100], Step [200/243], Loss: 0.3989\n",
      "Epoch [57/100], Step [220/243], Loss: 0.3018\n",
      "Epoch [57/100], Step [240/243], Loss: 1.0762\n",
      "\n",
      "train-loss: 2.1817, train-acc: 86.1040\n",
      "validation loss: 2.3992, validation acc: 73.6842\n",
      "\n",
      "Epoch 58\n",
      "\n",
      "Epoch [58/100], Step [0/243], Loss: 0.6113\n",
      "Epoch [58/100], Step [20/243], Loss: 0.4765\n",
      "Epoch [58/100], Step [40/243], Loss: 0.2183\n",
      "Epoch [58/100], Step [60/243], Loss: 0.3067\n",
      "Epoch [58/100], Step [80/243], Loss: 0.6162\n",
      "Epoch [58/100], Step [100/243], Loss: 0.2091\n",
      "Epoch [58/100], Step [120/243], Loss: 0.5317\n",
      "Epoch [58/100], Step [140/243], Loss: 0.7659\n",
      "Epoch [58/100], Step [160/243], Loss: 0.4218\n",
      "Epoch [58/100], Step [180/243], Loss: 0.5145\n",
      "Epoch [58/100], Step [200/243], Loss: 0.5461\n",
      "Epoch [58/100], Step [220/243], Loss: 1.2833\n",
      "Epoch [58/100], Step [240/243], Loss: 0.3356\n",
      "\n",
      "train-loss: 2.1515, train-acc: 88.5744\n",
      "validation loss: 2.3735, validation acc: 72.9323\n",
      "\n",
      "Epoch 59\n",
      "\n",
      "Epoch [59/100], Step [0/243], Loss: 0.3351\n",
      "Epoch [59/100], Step [20/243], Loss: 0.3837\n",
      "Epoch [59/100], Step [40/243], Loss: 0.2976\n",
      "Epoch [59/100], Step [60/243], Loss: 0.3163\n",
      "Epoch [59/100], Step [80/243], Loss: 1.3349\n",
      "Epoch [59/100], Step [100/243], Loss: 0.4719\n",
      "Epoch [59/100], Step [120/243], Loss: 0.2247\n",
      "Epoch [59/100], Step [140/243], Loss: 0.1545\n",
      "Epoch [59/100], Step [160/243], Loss: 0.7613\n",
      "Epoch [59/100], Step [180/243], Loss: 0.3002\n",
      "Epoch [59/100], Step [200/243], Loss: 0.2240\n",
      "Epoch [59/100], Step [220/243], Loss: 0.4770\n",
      "Epoch [59/100], Step [240/243], Loss: 0.2185\n",
      "\n",
      "train-loss: 2.1223, train-acc: 89.1405\n",
      "validation loss: 2.3483, validation acc: 72.9323\n",
      "\n",
      "Epoch 60\n",
      "\n",
      "Epoch [60/100], Step [0/243], Loss: 0.1641\n",
      "Epoch [60/100], Step [20/243], Loss: 0.4050\n",
      "Epoch [60/100], Step [40/243], Loss: 0.4184\n",
      "Epoch [60/100], Step [60/243], Loss: 0.4058\n",
      "Epoch [60/100], Step [80/243], Loss: 0.3013\n",
      "Epoch [60/100], Step [100/243], Loss: 0.6940\n",
      "Epoch [60/100], Step [120/243], Loss: 0.1676\n",
      "Epoch [60/100], Step [140/243], Loss: 0.1602\n",
      "Epoch [60/100], Step [160/243], Loss: 0.4193\n",
      "Epoch [60/100], Step [180/243], Loss: 0.9423\n",
      "Epoch [60/100], Step [200/243], Loss: 0.3722\n",
      "Epoch [60/100], Step [220/243], Loss: 0.7172\n",
      "Epoch [60/100], Step [240/243], Loss: 0.7243\n",
      "\n",
      "train-loss: 2.0940, train-acc: 88.0082\n",
      "validation loss: 2.3250, validation acc: 73.6842\n",
      "\n",
      "Epoch 61\n",
      "\n",
      "Epoch [61/100], Step [0/243], Loss: 0.1776\n",
      "Epoch [61/100], Step [20/243], Loss: 0.1357\n",
      "Epoch [61/100], Step [40/243], Loss: 0.3650\n",
      "Epoch [61/100], Step [60/243], Loss: 0.2449\n",
      "Epoch [61/100], Step [80/243], Loss: 0.4908\n",
      "Epoch [61/100], Step [100/243], Loss: 0.4232\n",
      "Epoch [61/100], Step [120/243], Loss: 0.6232\n",
      "Epoch [61/100], Step [140/243], Loss: 0.3247\n",
      "Epoch [61/100], Step [160/243], Loss: 0.2125\n",
      "Epoch [61/100], Step [180/243], Loss: 0.1895\n",
      "Epoch [61/100], Step [200/243], Loss: 0.1768\n",
      "Epoch [61/100], Step [220/243], Loss: 0.2975\n",
      "Epoch [61/100], Step [240/243], Loss: 0.1724\n",
      "\n",
      "train-loss: 2.0663, train-acc: 89.3978\n",
      "validation loss: 2.3010, validation acc: 75.9398\n",
      "\n",
      "Improvement-Detected, save-model\n",
      "Epoch 62\n",
      "\n",
      "Epoch [62/100], Step [0/243], Loss: 0.3167\n",
      "Epoch [62/100], Step [20/243], Loss: 0.0999\n",
      "Epoch [62/100], Step [40/243], Loss: 0.2789\n",
      "Epoch [62/100], Step [60/243], Loss: 0.1352\n",
      "Epoch [62/100], Step [80/243], Loss: 0.4593\n",
      "Epoch [62/100], Step [100/243], Loss: 0.2258\n",
      "Epoch [62/100], Step [120/243], Loss: 0.2358\n",
      "Epoch [62/100], Step [140/243], Loss: 0.0909\n",
      "Epoch [62/100], Step [160/243], Loss: 0.4884\n",
      "Epoch [62/100], Step [180/243], Loss: 0.1511\n",
      "Epoch [62/100], Step [200/243], Loss: 0.2444\n",
      "Epoch [62/100], Step [220/243], Loss: 0.3898\n",
      "Epoch [62/100], Step [240/243], Loss: 0.8753\n",
      "\n",
      "train-loss: 2.0391, train-acc: 90.0669\n",
      "validation loss: 2.2778, validation acc: 73.6842\n",
      "\n",
      "Epoch 63\n",
      "\n",
      "Epoch [63/100], Step [0/243], Loss: 0.1216\n",
      "Epoch [63/100], Step [20/243], Loss: 0.2780\n",
      "Epoch [63/100], Step [40/243], Loss: 0.9245\n",
      "Epoch [63/100], Step [60/243], Loss: 0.1336\n",
      "Epoch [63/100], Step [80/243], Loss: 0.1655\n",
      "Epoch [63/100], Step [100/243], Loss: 0.5972\n",
      "Epoch [63/100], Step [120/243], Loss: 0.1824\n",
      "Epoch [63/100], Step [140/243], Loss: 0.3445\n",
      "Epoch [63/100], Step [160/243], Loss: 0.2794\n",
      "Epoch [63/100], Step [180/243], Loss: 0.4707\n",
      "Epoch [63/100], Step [200/243], Loss: 0.0999\n",
      "Epoch [63/100], Step [220/243], Loss: 0.2635\n",
      "Epoch [63/100], Step [240/243], Loss: 0.3861\n",
      "\n",
      "train-loss: 2.0127, train-acc: 89.6037\n",
      "validation loss: 2.2569, validation acc: 71.4286\n",
      "\n",
      "Epoch 64\n",
      "\n",
      "Epoch [64/100], Step [0/243], Loss: 0.4898\n",
      "Epoch [64/100], Step [20/243], Loss: 0.2372\n",
      "Epoch [64/100], Step [40/243], Loss: 0.4027\n",
      "Epoch [64/100], Step [60/243], Loss: 0.2799\n",
      "Epoch [64/100], Step [80/243], Loss: 0.2761\n",
      "Epoch [64/100], Step [100/243], Loss: 0.0475\n",
      "Epoch [64/100], Step [120/243], Loss: 0.4250\n",
      "Epoch [64/100], Step [140/243], Loss: 0.2569\n",
      "Epoch [64/100], Step [160/243], Loss: 0.1490\n",
      "Epoch [64/100], Step [180/243], Loss: 0.0743\n",
      "Epoch [64/100], Step [200/243], Loss: 0.3450\n",
      "Epoch [64/100], Step [220/243], Loss: 0.1803\n",
      "Epoch [64/100], Step [240/243], Loss: 0.5551\n",
      "\n",
      "train-loss: 1.9866, train-acc: 90.4786\n",
      "validation loss: 2.2362, validation acc: 71.4286\n",
      "\n",
      "Epoch 65\n",
      "\n",
      "Epoch [65/100], Step [0/243], Loss: 0.6539\n",
      "Epoch [65/100], Step [20/243], Loss: 0.7474\n",
      "Epoch [65/100], Step [40/243], Loss: 0.3731\n",
      "Epoch [65/100], Step [60/243], Loss: 0.4118\n",
      "Epoch [65/100], Step [80/243], Loss: 1.4505\n",
      "Epoch [65/100], Step [100/243], Loss: 0.2119\n",
      "Epoch [65/100], Step [120/243], Loss: 0.4585\n",
      "Epoch [65/100], Step [140/243], Loss: 0.2415\n",
      "Epoch [65/100], Step [160/243], Loss: 0.0672\n",
      "Epoch [65/100], Step [180/243], Loss: 0.4576\n",
      "Epoch [65/100], Step [200/243], Loss: 0.5411\n",
      "Epoch [65/100], Step [220/243], Loss: 0.2067\n",
      "Epoch [65/100], Step [240/243], Loss: 0.0668\n",
      "\n",
      "train-loss: 1.9613, train-acc: 90.4272\n",
      "validation loss: 2.2160, validation acc: 74.4361\n",
      "\n",
      "Epoch 66\n",
      "\n",
      "Epoch [66/100], Step [0/243], Loss: 0.0849\n",
      "Epoch [66/100], Step [20/243], Loss: 0.6025\n",
      "Epoch [66/100], Step [40/243], Loss: 0.4020\n",
      "Epoch [66/100], Step [60/243], Loss: 0.1572\n",
      "Epoch [66/100], Step [80/243], Loss: 0.3145\n",
      "Epoch [66/100], Step [100/243], Loss: 0.0976\n",
      "Epoch [66/100], Step [120/243], Loss: 0.3972\n",
      "Epoch [66/100], Step [140/243], Loss: 0.2688\n",
      "Epoch [66/100], Step [160/243], Loss: 0.6540\n",
      "Epoch [66/100], Step [180/243], Loss: 0.1290\n",
      "Epoch [66/100], Step [200/243], Loss: 0.2887\n",
      "Epoch [66/100], Step [220/243], Loss: 0.4317\n",
      "Epoch [66/100], Step [240/243], Loss: 0.1135\n",
      "\n",
      "train-loss: 1.9365, train-acc: 91.6624\n",
      "validation loss: 2.1960, validation acc: 74.4361\n",
      "\n",
      "Epoch 67\n",
      "\n",
      "Epoch [67/100], Step [0/243], Loss: 0.2450\n",
      "Epoch [67/100], Step [20/243], Loss: 0.0539\n",
      "Epoch [67/100], Step [40/243], Loss: 0.1939\n",
      "Epoch [67/100], Step [60/243], Loss: 0.4150\n",
      "Epoch [67/100], Step [80/243], Loss: 0.1409\n",
      "Epoch [67/100], Step [100/243], Loss: 0.0652\n",
      "Epoch [67/100], Step [120/243], Loss: 0.7486\n",
      "Epoch [67/100], Step [140/243], Loss: 0.2176\n",
      "Epoch [67/100], Step [160/243], Loss: 0.2959\n",
      "Epoch [67/100], Step [180/243], Loss: 0.2563\n",
      "Epoch [67/100], Step [200/243], Loss: 0.1626\n",
      "Epoch [67/100], Step [220/243], Loss: 0.2360\n",
      "Epoch [67/100], Step [240/243], Loss: 0.1423\n",
      "\n",
      "train-loss: 1.9120, train-acc: 93.1034\n",
      "validation loss: 2.1783, validation acc: 69.9248\n",
      "\n",
      "Epoch 68\n",
      "\n",
      "Epoch [68/100], Step [0/243], Loss: 0.7006\n",
      "Epoch [68/100], Step [20/243], Loss: 0.2898\n",
      "Epoch [68/100], Step [40/243], Loss: 0.0784\n",
      "Epoch [68/100], Step [60/243], Loss: 0.1491\n",
      "Epoch [68/100], Step [80/243], Loss: 0.1457\n",
      "Epoch [68/100], Step [100/243], Loss: 0.3625\n",
      "Epoch [68/100], Step [120/243], Loss: 0.0624\n",
      "Epoch [68/100], Step [140/243], Loss: 0.2469\n",
      "Epoch [68/100], Step [160/243], Loss: 0.0763\n",
      "Epoch [68/100], Step [180/243], Loss: 0.2344\n",
      "Epoch [68/100], Step [200/243], Loss: 0.3099\n",
      "Epoch [68/100], Step [220/243], Loss: 0.1123\n",
      "Epoch [68/100], Step [240/243], Loss: 1.1094\n",
      "\n",
      "train-loss: 1.8882, train-acc: 92.2800\n",
      "validation loss: 2.1611, validation acc: 69.9248\n",
      "\n",
      "Epoch 69\n",
      "\n",
      "Epoch [69/100], Step [0/243], Loss: 0.4854\n",
      "Epoch [69/100], Step [20/243], Loss: 0.0893\n",
      "Epoch [69/100], Step [40/243], Loss: 0.2397\n",
      "Epoch [69/100], Step [60/243], Loss: 0.0779\n",
      "Epoch [69/100], Step [80/243], Loss: 0.0573\n",
      "Epoch [69/100], Step [100/243], Loss: 0.0578\n",
      "Epoch [69/100], Step [120/243], Loss: 0.0637\n",
      "Epoch [69/100], Step [140/243], Loss: 0.1528\n",
      "Epoch [69/100], Step [160/243], Loss: 0.2396\n",
      "Epoch [69/100], Step [180/243], Loss: 0.3790\n",
      "Epoch [69/100], Step [200/243], Loss: 0.2904\n",
      "Epoch [69/100], Step [220/243], Loss: 0.1607\n",
      "Epoch [69/100], Step [240/243], Loss: 0.0866\n",
      "\n",
      "train-loss: 1.8649, train-acc: 91.9712\n",
      "validation loss: 2.1432, validation acc: 72.9323\n",
      "\n",
      "Epoch 70\n",
      "\n",
      "Epoch [70/100], Step [0/243], Loss: 0.1823\n",
      "Epoch [70/100], Step [20/243], Loss: 0.0489\n",
      "Epoch [70/100], Step [40/243], Loss: 0.1021\n",
      "Epoch [70/100], Step [60/243], Loss: 0.3741\n",
      "Epoch [70/100], Step [80/243], Loss: 0.1739\n",
      "Epoch [70/100], Step [100/243], Loss: 0.6284\n",
      "Epoch [70/100], Step [120/243], Loss: 0.2999\n",
      "Epoch [70/100], Step [140/243], Loss: 0.2841\n",
      "Epoch [70/100], Step [160/243], Loss: 0.3671\n",
      "Epoch [70/100], Step [180/243], Loss: 0.3414\n",
      "Epoch [70/100], Step [200/243], Loss: 0.1405\n",
      "Epoch [70/100], Step [220/243], Loss: 0.3815\n",
      "Epoch [70/100], Step [240/243], Loss: 0.0716\n",
      "\n",
      "train-loss: 1.8422, train-acc: 93.3608\n",
      "validation loss: 2.1256, validation acc: 72.1805\n",
      "\n",
      "Epoch 71\n",
      "\n",
      "Epoch [71/100], Step [0/243], Loss: 0.6862\n",
      "Epoch [71/100], Step [20/243], Loss: 0.0913\n",
      "Epoch [71/100], Step [40/243], Loss: 0.2477\n",
      "Epoch [71/100], Step [60/243], Loss: 0.0660\n",
      "Epoch [71/100], Step [80/243], Loss: 0.1126\n",
      "Epoch [71/100], Step [100/243], Loss: 1.1989\n",
      "Epoch [71/100], Step [120/243], Loss: 0.4489\n",
      "Epoch [71/100], Step [140/243], Loss: 0.1181\n",
      "Epoch [71/100], Step [160/243], Loss: 0.1411\n",
      "Epoch [71/100], Step [180/243], Loss: 0.1571\n",
      "Epoch [71/100], Step [200/243], Loss: 0.2216\n",
      "Epoch [71/100], Step [220/243], Loss: 0.3203\n",
      "Epoch [71/100], Step [240/243], Loss: 0.1076\n",
      "\n",
      "train-loss: 1.8200, train-acc: 93.5666\n",
      "validation loss: 2.1096, validation acc: 71.4286\n",
      "\n",
      "Epoch 72\n",
      "\n",
      "Epoch [72/100], Step [0/243], Loss: 0.1693\n",
      "Epoch [72/100], Step [20/243], Loss: 0.3878\n",
      "Epoch [72/100], Step [40/243], Loss: 0.1615\n",
      "Epoch [72/100], Step [60/243], Loss: 0.6594\n",
      "Epoch [72/100], Step [80/243], Loss: 0.1365\n",
      "Epoch [72/100], Step [100/243], Loss: 0.3743\n",
      "Epoch [72/100], Step [120/243], Loss: 0.0690\n",
      "Epoch [72/100], Step [140/243], Loss: 0.4592\n",
      "Epoch [72/100], Step [160/243], Loss: 0.2385\n",
      "Epoch [72/100], Step [180/243], Loss: 0.2079\n",
      "Epoch [72/100], Step [200/243], Loss: 0.0832\n",
      "Epoch [72/100], Step [220/243], Loss: 0.1617\n",
      "Epoch [72/100], Step [240/243], Loss: 0.0643\n",
      "\n",
      "train-loss: 1.7985, train-acc: 93.6696\n",
      "validation loss: 2.0947, validation acc: 71.4286\n",
      "\n",
      "Epoch 73\n",
      "\n",
      "Epoch [73/100], Step [0/243], Loss: 0.0773\n",
      "Epoch [73/100], Step [20/243], Loss: 0.3902\n",
      "Epoch [73/100], Step [40/243], Loss: 0.1591\n",
      "Epoch [73/100], Step [60/243], Loss: 0.4008\n",
      "Epoch [73/100], Step [80/243], Loss: 0.0771\n",
      "Epoch [73/100], Step [100/243], Loss: 0.8539\n",
      "Epoch [73/100], Step [120/243], Loss: 0.2297\n",
      "Epoch [73/100], Step [140/243], Loss: 0.2524\n",
      "Epoch [73/100], Step [160/243], Loss: 0.0373\n",
      "Epoch [73/100], Step [180/243], Loss: 0.1934\n",
      "Epoch [73/100], Step [200/243], Loss: 0.2695\n",
      "Epoch [73/100], Step [220/243], Loss: 0.1506\n",
      "Epoch [73/100], Step [240/243], Loss: 0.8186\n",
      "\n",
      "train-loss: 1.7772, train-acc: 93.8240\n",
      "validation loss: 2.0791, validation acc: 71.4286\n",
      "\n",
      "Epoch 74\n",
      "\n",
      "Epoch [74/100], Step [0/243], Loss: 0.0818\n",
      "Epoch [74/100], Step [20/243], Loss: 0.0834\n",
      "Epoch [74/100], Step [40/243], Loss: 0.6089\n",
      "Epoch [74/100], Step [60/243], Loss: 0.0695\n",
      "Epoch [74/100], Step [80/243], Loss: 0.1290\n",
      "Epoch [74/100], Step [100/243], Loss: 0.1002\n",
      "Epoch [74/100], Step [120/243], Loss: 0.1527\n",
      "Epoch [74/100], Step [140/243], Loss: 0.1063\n",
      "Epoch [74/100], Step [160/243], Loss: 0.4639\n",
      "Epoch [74/100], Step [180/243], Loss: 0.5405\n",
      "Epoch [74/100], Step [200/243], Loss: 0.0351\n",
      "Epoch [74/100], Step [220/243], Loss: 0.7347\n",
      "Epoch [74/100], Step [240/243], Loss: 0.0301\n",
      "\n",
      "train-loss: 1.7562, train-acc: 94.8019\n",
      "validation loss: 2.0627, validation acc: 73.6842\n",
      "\n",
      "Epoch 75\n",
      "\n",
      "Epoch [75/100], Step [0/243], Loss: 0.2012\n",
      "Epoch [75/100], Step [20/243], Loss: 0.0770\n",
      "Epoch [75/100], Step [40/243], Loss: 0.0281\n",
      "Epoch [75/100], Step [60/243], Loss: 0.2604\n",
      "Epoch [75/100], Step [80/243], Loss: 0.1040\n",
      "Epoch [75/100], Step [100/243], Loss: 0.1157\n",
      "Epoch [75/100], Step [120/243], Loss: 0.1504\n",
      "Epoch [75/100], Step [140/243], Loss: 0.0857\n",
      "Epoch [75/100], Step [160/243], Loss: 0.2182\n",
      "Epoch [75/100], Step [180/243], Loss: 0.0748\n",
      "Epoch [75/100], Step [200/243], Loss: 0.0967\n",
      "Epoch [75/100], Step [220/243], Loss: 0.3059\n",
      "Epoch [75/100], Step [240/243], Loss: 0.0409\n",
      "\n",
      "train-loss: 1.7354, train-acc: 95.4195\n",
      "validation loss: 2.0476, validation acc: 69.1729\n",
      "\n",
      "Epoch 76\n",
      "\n",
      "Epoch [76/100], Step [0/243], Loss: 0.0236\n",
      "Epoch [76/100], Step [20/243], Loss: 0.0377\n",
      "Epoch [76/100], Step [40/243], Loss: 0.2298\n",
      "Epoch [76/100], Step [60/243], Loss: 0.1321\n",
      "Epoch [76/100], Step [80/243], Loss: 0.0527\n",
      "Epoch [76/100], Step [100/243], Loss: 0.3429\n",
      "Epoch [76/100], Step [120/243], Loss: 0.0494\n",
      "Epoch [76/100], Step [140/243], Loss: 0.2505\n",
      "Epoch [76/100], Step [160/243], Loss: 0.1656\n",
      "Epoch [76/100], Step [180/243], Loss: 0.0443\n",
      "Epoch [76/100], Step [200/243], Loss: 0.2798\n",
      "Epoch [76/100], Step [220/243], Loss: 0.0936\n",
      "Epoch [76/100], Step [240/243], Loss: 0.2010\n",
      "\n",
      "train-loss: 1.7156, train-acc: 94.1328\n",
      "validation loss: 2.0333, validation acc: 71.4286\n",
      "\n",
      "Epoch 77\n",
      "\n",
      "Epoch [77/100], Step [0/243], Loss: 0.0621\n",
      "Epoch [77/100], Step [20/243], Loss: 0.0677\n",
      "Epoch [77/100], Step [40/243], Loss: 0.3733\n",
      "Epoch [77/100], Step [60/243], Loss: 0.0516\n",
      "Epoch [77/100], Step [80/243], Loss: 0.1723\n",
      "Epoch [77/100], Step [100/243], Loss: 0.4622\n",
      "Epoch [77/100], Step [120/243], Loss: 0.1243\n",
      "Epoch [77/100], Step [140/243], Loss: 0.0560\n",
      "Epoch [77/100], Step [160/243], Loss: 0.2763\n",
      "Epoch [77/100], Step [180/243], Loss: 0.2056\n",
      "Epoch [77/100], Step [200/243], Loss: 0.3797\n",
      "Epoch [77/100], Step [220/243], Loss: 0.3171\n",
      "Epoch [77/100], Step [240/243], Loss: 0.1267\n",
      "\n",
      "train-loss: 1.6958, train-acc: 95.3165\n",
      "validation loss: 2.0190, validation acc: 71.4286\n",
      "\n",
      "Epoch 78\n",
      "\n",
      "Epoch [78/100], Step [0/243], Loss: 0.0618\n",
      "Epoch [78/100], Step [20/243], Loss: 0.0625\n",
      "Epoch [78/100], Step [40/243], Loss: 0.0516\n",
      "Epoch [78/100], Step [60/243], Loss: 0.2586\n",
      "Epoch [78/100], Step [80/243], Loss: 0.2679\n",
      "Epoch [78/100], Step [100/243], Loss: 0.1843\n",
      "Epoch [78/100], Step [120/243], Loss: 0.0235\n",
      "Epoch [78/100], Step [140/243], Loss: 0.1610\n",
      "Epoch [78/100], Step [160/243], Loss: 0.2734\n",
      "Epoch [78/100], Step [180/243], Loss: 0.1409\n",
      "Epoch [78/100], Step [200/243], Loss: 0.1749\n",
      "Epoch [78/100], Step [220/243], Loss: 0.0814\n",
      "Epoch [78/100], Step [240/243], Loss: 0.4480\n",
      "\n",
      "train-loss: 1.6767, train-acc: 95.3165\n",
      "validation loss: 2.0049, validation acc: 72.9323\n",
      "\n",
      "Epoch 79\n",
      "\n",
      "Epoch [79/100], Step [0/243], Loss: 0.1519\n",
      "Epoch [79/100], Step [20/243], Loss: 0.1309\n",
      "Epoch [79/100], Step [40/243], Loss: 0.1827\n",
      "Epoch [79/100], Step [60/243], Loss: 0.7713\n",
      "Epoch [79/100], Step [80/243], Loss: 0.1531\n",
      "Epoch [79/100], Step [100/243], Loss: 0.3282\n",
      "Epoch [79/100], Step [120/243], Loss: 0.1153\n",
      "Epoch [79/100], Step [140/243], Loss: 0.1530\n",
      "Epoch [79/100], Step [160/243], Loss: 0.2491\n",
      "Epoch [79/100], Step [180/243], Loss: 0.1320\n",
      "Epoch [79/100], Step [200/243], Loss: 0.2372\n",
      "Epoch [79/100], Step [220/243], Loss: 0.3577\n",
      "Epoch [79/100], Step [240/243], Loss: 0.4251\n",
      "\n",
      "train-loss: 1.6581, train-acc: 94.2872\n",
      "validation loss: 1.9917, validation acc: 71.4286\n",
      "\n",
      "Epoch 80\n",
      "\n",
      "Epoch [80/100], Step [0/243], Loss: 0.0597\n",
      "Epoch [80/100], Step [20/243], Loss: 0.1593\n",
      "Epoch [80/100], Step [40/243], Loss: 0.0476\n",
      "Epoch [80/100], Step [60/243], Loss: 0.0977\n",
      "Epoch [80/100], Step [80/243], Loss: 0.0220\n",
      "Epoch [80/100], Step [100/243], Loss: 0.0892\n",
      "Epoch [80/100], Step [120/243], Loss: 0.7734\n",
      "Epoch [80/100], Step [140/243], Loss: 0.1778\n",
      "Epoch [80/100], Step [160/243], Loss: 0.3760\n",
      "Epoch [80/100], Step [180/243], Loss: 0.0654\n",
      "Epoch [80/100], Step [200/243], Loss: 0.4282\n",
      "Epoch [80/100], Step [220/243], Loss: 0.0669\n",
      "Epoch [80/100], Step [240/243], Loss: 0.2431\n",
      "\n",
      "train-loss: 1.6400, train-acc: 94.5445\n",
      "validation loss: 1.9795, validation acc: 69.9248\n",
      "\n",
      "Epoch 81\n",
      "\n",
      "Epoch [81/100], Step [0/243], Loss: 0.0978\n",
      "Epoch [81/100], Step [20/243], Loss: 0.0593\n",
      "Epoch [81/100], Step [40/243], Loss: 0.0459\n",
      "Epoch [81/100], Step [60/243], Loss: 0.4176\n",
      "Epoch [81/100], Step [80/243], Loss: 0.1830\n",
      "Epoch [81/100], Step [100/243], Loss: 0.4131\n",
      "Epoch [81/100], Step [120/243], Loss: 0.1726\n",
      "Epoch [81/100], Step [140/243], Loss: 0.0461\n",
      "Epoch [81/100], Step [160/243], Loss: 0.0583\n",
      "Epoch [81/100], Step [180/243], Loss: 0.1360\n",
      "Epoch [81/100], Step [200/243], Loss: 0.0666\n",
      "Epoch [81/100], Step [220/243], Loss: 0.0862\n",
      "Epoch [81/100], Step [240/243], Loss: 0.0453\n",
      "\n",
      "train-loss: 1.6222, train-acc: 95.1107\n",
      "validation loss: 1.9672, validation acc: 74.4361\n",
      "\n",
      "Epoch 82\n",
      "\n",
      "Epoch [82/100], Step [0/243], Loss: 0.0414\n",
      "Epoch [82/100], Step [20/243], Loss: 0.2011\n",
      "Epoch [82/100], Step [40/243], Loss: 0.3080\n",
      "Epoch [82/100], Step [60/243], Loss: 0.1601\n",
      "Epoch [82/100], Step [80/243], Loss: 0.1576\n",
      "Epoch [82/100], Step [100/243], Loss: 0.1742\n",
      "Epoch [82/100], Step [120/243], Loss: 0.0939\n",
      "Epoch [82/100], Step [140/243], Loss: 0.6113\n",
      "Epoch [82/100], Step [160/243], Loss: 0.1113\n",
      "Epoch [82/100], Step [180/243], Loss: 0.3478\n",
      "Epoch [82/100], Step [200/243], Loss: 0.0245\n",
      "Epoch [82/100], Step [220/243], Loss: 0.4154\n",
      "Epoch [82/100], Step [240/243], Loss: 0.0868\n",
      "\n",
      "train-loss: 1.6046, train-acc: 96.2944\n",
      "validation loss: 1.9551, validation acc: 72.1805\n",
      "\n",
      "Epoch 83\n",
      "\n",
      "Epoch [83/100], Step [0/243], Loss: 0.4078\n",
      "Epoch [83/100], Step [20/243], Loss: 0.2512\n",
      "Epoch [83/100], Step [40/243], Loss: 0.2873\n",
      "Epoch [83/100], Step [60/243], Loss: 0.1684\n",
      "Epoch [83/100], Step [80/243], Loss: 0.1862\n",
      "Epoch [83/100], Step [100/243], Loss: 0.0591\n",
      "Epoch [83/100], Step [120/243], Loss: 0.0594\n",
      "Epoch [83/100], Step [140/243], Loss: 0.1341\n",
      "Epoch [83/100], Step [160/243], Loss: 0.1298\n",
      "Epoch [83/100], Step [180/243], Loss: 0.0283\n",
      "Epoch [83/100], Step [200/243], Loss: 0.0595\n",
      "Epoch [83/100], Step [220/243], Loss: 0.2448\n",
      "Epoch [83/100], Step [240/243], Loss: 0.0671\n",
      "\n",
      "train-loss: 1.5872, train-acc: 96.3459\n",
      "validation loss: 1.9441, validation acc: 72.1805\n",
      "\n",
      "Epoch 84\n",
      "\n",
      "Epoch [84/100], Step [0/243], Loss: 0.1246\n",
      "Epoch [84/100], Step [20/243], Loss: 0.1068\n",
      "Epoch [84/100], Step [40/243], Loss: 0.0421\n",
      "Epoch [84/100], Step [60/243], Loss: 0.2307\n",
      "Epoch [84/100], Step [80/243], Loss: 0.1198\n",
      "Epoch [84/100], Step [100/243], Loss: 0.3627\n",
      "Epoch [84/100], Step [120/243], Loss: 0.0561\n",
      "Epoch [84/100], Step [140/243], Loss: 0.0513\n",
      "Epoch [84/100], Step [160/243], Loss: 0.0276\n",
      "Epoch [84/100], Step [180/243], Loss: 0.5385\n",
      "Epoch [84/100], Step [200/243], Loss: 0.0357\n",
      "Epoch [84/100], Step [220/243], Loss: 0.5528\n",
      "Epoch [84/100], Step [240/243], Loss: 0.0923\n",
      "\n",
      "train-loss: 1.5704, train-acc: 95.6253\n",
      "validation loss: 1.9325, validation acc: 72.9323\n",
      "\n",
      "Epoch 85\n",
      "\n",
      "Epoch [85/100], Step [0/243], Loss: 0.0874\n",
      "Epoch [85/100], Step [20/243], Loss: 0.4745\n",
      "Epoch [85/100], Step [40/243], Loss: 0.0442\n",
      "Epoch [85/100], Step [60/243], Loss: 0.0488\n",
      "Epoch [85/100], Step [80/243], Loss: 0.0306\n",
      "Epoch [85/100], Step [100/243], Loss: 0.1872\n",
      "Epoch [85/100], Step [120/243], Loss: 0.6213\n",
      "Epoch [85/100], Step [140/243], Loss: 0.0490\n",
      "Epoch [85/100], Step [160/243], Loss: 0.1794\n",
      "Epoch [85/100], Step [180/243], Loss: 0.5921\n",
      "Epoch [85/100], Step [200/243], Loss: 0.1440\n",
      "Epoch [85/100], Step [220/243], Loss: 0.2210\n",
      "Epoch [85/100], Step [240/243], Loss: 0.0912\n",
      "\n",
      "train-loss: 1.5541, train-acc: 95.4195\n",
      "validation loss: 1.9205, validation acc: 74.4361\n",
      "\n",
      "Epoch 86\n",
      "\n",
      "Epoch [86/100], Step [0/243], Loss: 0.7123\n",
      "Epoch [86/100], Step [20/243], Loss: 0.0292\n",
      "Epoch [86/100], Step [40/243], Loss: 0.1873\n",
      "Epoch [86/100], Step [60/243], Loss: 0.0677\n",
      "Epoch [86/100], Step [80/243], Loss: 0.2667\n",
      "Epoch [86/100], Step [100/243], Loss: 0.0330\n",
      "Epoch [86/100], Step [120/243], Loss: 0.0568\n",
      "Epoch [86/100], Step [140/243], Loss: 0.1678\n",
      "Epoch [86/100], Step [160/243], Loss: 0.2604\n",
      "Epoch [86/100], Step [180/243], Loss: 0.0291\n",
      "Epoch [86/100], Step [200/243], Loss: 0.1326\n",
      "Epoch [86/100], Step [220/243], Loss: 0.0514\n",
      "Epoch [86/100], Step [240/243], Loss: 0.0629\n",
      "\n",
      "train-loss: 1.5379, train-acc: 96.0885\n",
      "validation loss: 1.9094, validation acc: 73.6842\n",
      "\n",
      "Epoch 87\n",
      "\n",
      "Epoch [87/100], Step [0/243], Loss: 0.0654\n",
      "Epoch [87/100], Step [20/243], Loss: 0.0505\n",
      "Epoch [87/100], Step [40/243], Loss: 0.0385\n",
      "Epoch [87/100], Step [60/243], Loss: 0.0944\n",
      "Epoch [87/100], Step [80/243], Loss: 0.1884\n",
      "Epoch [87/100], Step [100/243], Loss: 0.0711\n",
      "Epoch [87/100], Step [120/243], Loss: 0.1255\n",
      "Epoch [87/100], Step [140/243], Loss: 0.0624\n",
      "Epoch [87/100], Step [160/243], Loss: 0.1112\n",
      "Epoch [87/100], Step [180/243], Loss: 0.0554\n",
      "Epoch [87/100], Step [200/243], Loss: 0.0318\n",
      "Epoch [87/100], Step [220/243], Loss: 0.4941\n",
      "Epoch [87/100], Step [240/243], Loss: 0.2114\n",
      "\n",
      "train-loss: 1.5220, train-acc: 96.6032\n",
      "validation loss: 1.8988, validation acc: 74.4361\n",
      "\n",
      "Epoch 88\n",
      "\n",
      "Epoch [88/100], Step [0/243], Loss: 0.2649\n",
      "Epoch [88/100], Step [20/243], Loss: 0.1444\n",
      "Epoch [88/100], Step [40/243], Loss: 0.0622\n",
      "Epoch [88/100], Step [60/243], Loss: 0.0411\n",
      "Epoch [88/100], Step [80/243], Loss: 0.1809\n",
      "Epoch [88/100], Step [100/243], Loss: 0.0227\n",
      "Epoch [88/100], Step [120/243], Loss: 0.0905\n",
      "Epoch [88/100], Step [140/243], Loss: 0.0933\n",
      "Epoch [88/100], Step [160/243], Loss: 0.0270\n",
      "Epoch [88/100], Step [180/243], Loss: 0.1000\n",
      "Epoch [88/100], Step [200/243], Loss: 0.0598\n",
      "Epoch [88/100], Step [220/243], Loss: 0.3686\n",
      "Epoch [88/100], Step [240/243], Loss: 0.1769\n",
      "\n",
      "train-loss: 1.5063, train-acc: 96.9635\n",
      "validation loss: 1.8882, validation acc: 72.1805\n",
      "\n",
      "Epoch 89\n",
      "\n",
      "Epoch [89/100], Step [0/243], Loss: 0.1009\n",
      "Epoch [89/100], Step [20/243], Loss: 0.0159\n",
      "Epoch [89/100], Step [40/243], Loss: 0.1459\n",
      "Epoch [89/100], Step [60/243], Loss: 0.0366\n",
      "Epoch [89/100], Step [80/243], Loss: 0.0723\n",
      "Epoch [89/100], Step [100/243], Loss: 0.2246\n",
      "Epoch [89/100], Step [120/243], Loss: 0.2237\n",
      "Epoch [89/100], Step [140/243], Loss: 0.0343\n",
      "Epoch [89/100], Step [160/243], Loss: 0.1584\n",
      "Epoch [89/100], Step [180/243], Loss: 0.1067\n",
      "Epoch [89/100], Step [200/243], Loss: 0.1992\n",
      "Epoch [89/100], Step [220/243], Loss: 0.5150\n",
      "Epoch [89/100], Step [240/243], Loss: 0.0113\n",
      "\n",
      "train-loss: 1.4910, train-acc: 96.7576\n",
      "validation loss: 1.8784, validation acc: 71.4286\n",
      "\n",
      "Epoch 90\n",
      "\n",
      "Epoch [90/100], Step [0/243], Loss: 0.0982\n",
      "Epoch [90/100], Step [20/243], Loss: 0.0477\n",
      "Epoch [90/100], Step [40/243], Loss: 0.2466\n",
      "Epoch [90/100], Step [60/243], Loss: 0.1590\n",
      "Epoch [90/100], Step [80/243], Loss: 0.0112\n",
      "Epoch [90/100], Step [100/243], Loss: 0.0999\n",
      "Epoch [90/100], Step [120/243], Loss: 0.4842\n",
      "Epoch [90/100], Step [140/243], Loss: 0.0541\n",
      "Epoch [90/100], Step [160/243], Loss: 0.1229\n",
      "Epoch [90/100], Step [180/243], Loss: 0.0886\n",
      "Epoch [90/100], Step [200/243], Loss: 0.1843\n",
      "Epoch [90/100], Step [220/243], Loss: 0.0634\n",
      "Epoch [90/100], Step [240/243], Loss: 0.0481\n",
      "\n",
      "train-loss: 1.4760, train-acc: 96.2944\n",
      "validation loss: 1.8696, validation acc: 69.9248\n",
      "\n",
      "Epoch 91\n",
      "\n",
      "Epoch [91/100], Step [0/243], Loss: 0.2172\n",
      "Epoch [91/100], Step [20/243], Loss: 0.1377\n",
      "Epoch [91/100], Step [40/243], Loss: 0.5711\n",
      "Epoch [91/100], Step [60/243], Loss: 0.1072\n",
      "Epoch [91/100], Step [80/243], Loss: 0.0953\n",
      "Epoch [91/100], Step [100/243], Loss: 0.0436\n",
      "Epoch [91/100], Step [120/243], Loss: 0.0429\n",
      "Epoch [91/100], Step [140/243], Loss: 0.1179\n",
      "Epoch [91/100], Step [160/243], Loss: 0.1595\n",
      "Epoch [91/100], Step [180/243], Loss: 0.1172\n",
      "Epoch [91/100], Step [200/243], Loss: 0.0866\n",
      "Epoch [91/100], Step [220/243], Loss: 0.0382\n",
      "Epoch [91/100], Step [240/243], Loss: 1.1204\n",
      "\n",
      "train-loss: 1.4614, train-acc: 96.6032\n",
      "validation loss: 1.8610, validation acc: 69.9248\n",
      "\n",
      "Epoch 92\n",
      "\n",
      "Epoch [92/100], Step [0/243], Loss: 0.2338\n",
      "Epoch [92/100], Step [20/243], Loss: 0.0260\n",
      "Epoch [92/100], Step [40/243], Loss: 0.0311\n",
      "Epoch [92/100], Step [60/243], Loss: 0.3770\n",
      "Epoch [92/100], Step [80/243], Loss: 0.1289\n",
      "Epoch [92/100], Step [100/243], Loss: 1.0020\n",
      "Epoch [92/100], Step [120/243], Loss: 0.0425\n",
      "Epoch [92/100], Step [140/243], Loss: 0.0223\n",
      "Epoch [92/100], Step [160/243], Loss: 0.1081\n",
      "Epoch [92/100], Step [180/243], Loss: 0.0273\n",
      "Epoch [92/100], Step [200/243], Loss: 0.0345\n",
      "Epoch [92/100], Step [220/243], Loss: 0.0442\n",
      "Epoch [92/100], Step [240/243], Loss: 0.4120\n",
      "\n",
      "train-loss: 1.4470, train-acc: 97.2723\n",
      "validation loss: 1.8524, validation acc: 66.9173\n",
      "\n",
      "Epoch 93\n",
      "\n",
      "Epoch [93/100], Step [0/243], Loss: 0.0636\n",
      "Epoch [93/100], Step [20/243], Loss: 0.0314\n",
      "Epoch [93/100], Step [40/243], Loss: 0.0169\n",
      "Epoch [93/100], Step [60/243], Loss: 0.1345\n",
      "Epoch [93/100], Step [80/243], Loss: 0.0388\n",
      "Epoch [93/100], Step [100/243], Loss: 0.0603\n",
      "Epoch [93/100], Step [120/243], Loss: 0.0438\n",
      "Epoch [93/100], Step [140/243], Loss: 0.2849\n",
      "Epoch [93/100], Step [160/243], Loss: 0.0393\n",
      "Epoch [93/100], Step [180/243], Loss: 0.1040\n",
      "Epoch [93/100], Step [200/243], Loss: 0.1019\n",
      "Epoch [93/100], Step [220/243], Loss: 0.1782\n",
      "Epoch [93/100], Step [240/243], Loss: 0.3398\n",
      "\n",
      "train-loss: 1.4327, train-acc: 97.4781\n",
      "validation loss: 1.8431, validation acc: 72.9323\n",
      "\n",
      "Epoch 94\n",
      "\n",
      "Epoch [94/100], Step [0/243], Loss: 0.0704\n",
      "Epoch [94/100], Step [20/243], Loss: 0.0710\n",
      "Epoch [94/100], Step [40/243], Loss: 0.0451\n",
      "Epoch [94/100], Step [60/243], Loss: 0.0209\n",
      "Epoch [94/100], Step [80/243], Loss: 0.3766\n",
      "Epoch [94/100], Step [100/243], Loss: 0.0886\n",
      "Epoch [94/100], Step [120/243], Loss: 0.0864\n",
      "Epoch [94/100], Step [140/243], Loss: 0.0134\n",
      "Epoch [94/100], Step [160/243], Loss: 0.0775\n",
      "Epoch [94/100], Step [180/243], Loss: 0.1655\n",
      "Epoch [94/100], Step [200/243], Loss: 0.0658\n",
      "Epoch [94/100], Step [220/243], Loss: 0.2942\n",
      "Epoch [94/100], Step [240/243], Loss: 0.0428\n",
      "\n",
      "train-loss: 1.4188, train-acc: 97.4781\n",
      "validation loss: 1.8344, validation acc: 69.1729\n",
      "\n",
      "Epoch 95\n",
      "\n",
      "Epoch [95/100], Step [0/243], Loss: 0.0361\n",
      "Epoch [95/100], Step [20/243], Loss: 0.3435\n",
      "Epoch [95/100], Step [40/243], Loss: 0.1251\n",
      "Epoch [95/100], Step [60/243], Loss: 0.1174\n",
      "Epoch [95/100], Step [80/243], Loss: 0.0282\n",
      "Epoch [95/100], Step [100/243], Loss: 0.0279\n",
      "Epoch [95/100], Step [120/243], Loss: 0.2410\n",
      "Epoch [95/100], Step [140/243], Loss: 0.0925\n",
      "Epoch [95/100], Step [160/243], Loss: 1.0338\n",
      "Epoch [95/100], Step [180/243], Loss: 0.1538\n",
      "Epoch [95/100], Step [200/243], Loss: 0.1205\n",
      "Epoch [95/100], Step [220/243], Loss: 0.0347\n",
      "Epoch [95/100], Step [240/243], Loss: 0.0295\n",
      "\n",
      "train-loss: 1.4053, train-acc: 96.4488\n",
      "validation loss: 1.8252, validation acc: 71.4286\n",
      "\n",
      "Epoch 96\n",
      "\n",
      "Epoch [96/100], Step [0/243], Loss: 0.2810\n",
      "Epoch [96/100], Step [20/243], Loss: 0.0268\n",
      "Epoch [96/100], Step [40/243], Loss: 0.1281\n",
      "Epoch [96/100], Step [60/243], Loss: 0.0452\n",
      "Epoch [96/100], Step [80/243], Loss: 0.0711\n",
      "Epoch [96/100], Step [100/243], Loss: 0.0179\n",
      "Epoch [96/100], Step [120/243], Loss: 0.0689\n",
      "Epoch [96/100], Step [140/243], Loss: 0.0510\n",
      "Epoch [96/100], Step [160/243], Loss: 0.2024\n",
      "Epoch [96/100], Step [180/243], Loss: 0.6817\n",
      "Epoch [96/100], Step [200/243], Loss: 0.0533\n",
      "Epoch [96/100], Step [220/243], Loss: 0.0244\n",
      "Epoch [96/100], Step [240/243], Loss: 0.2944\n",
      "\n",
      "train-loss: 1.3921, train-acc: 96.6032\n",
      "validation loss: 1.8167, validation acc: 73.6842\n",
      "\n",
      "Epoch 97\n",
      "\n",
      "Epoch [97/100], Step [0/243], Loss: 0.4975\n",
      "Epoch [97/100], Step [20/243], Loss: 0.0332\n",
      "Epoch [97/100], Step [40/243], Loss: 0.0359\n",
      "Epoch [97/100], Step [60/243], Loss: 0.0871\n",
      "Epoch [97/100], Step [80/243], Loss: 0.0740\n",
      "Epoch [97/100], Step [100/243], Loss: 0.1959\n",
      "Epoch [97/100], Step [120/243], Loss: 0.1814\n",
      "Epoch [97/100], Step [140/243], Loss: 0.0405\n",
      "Epoch [97/100], Step [160/243], Loss: 0.0731\n",
      "Epoch [97/100], Step [180/243], Loss: 0.0154\n",
      "Epoch [97/100], Step [200/243], Loss: 0.0738\n",
      "Epoch [97/100], Step [220/243], Loss: 0.0956\n",
      "Epoch [97/100], Step [240/243], Loss: 0.1816\n",
      "\n",
      "train-loss: 1.3789, train-acc: 97.4267\n",
      "validation loss: 1.8087, validation acc: 72.1805\n",
      "\n",
      "Epoch 98\n",
      "\n",
      "Epoch [98/100], Step [0/243], Loss: 0.5584\n",
      "Epoch [98/100], Step [20/243], Loss: 0.0522\n",
      "Epoch [98/100], Step [40/243], Loss: 0.0617\n",
      "Epoch [98/100], Step [60/243], Loss: 0.0600\n",
      "Epoch [98/100], Step [80/243], Loss: 0.0504\n",
      "Epoch [98/100], Step [100/243], Loss: 0.0138\n",
      "Epoch [98/100], Step [120/243], Loss: 0.0337\n",
      "Epoch [98/100], Step [140/243], Loss: 0.0839\n",
      "Epoch [98/100], Step [160/243], Loss: 0.1331\n",
      "Epoch [98/100], Step [180/243], Loss: 0.0815\n",
      "Epoch [98/100], Step [200/243], Loss: 0.0319\n",
      "Epoch [98/100], Step [220/243], Loss: 0.0737\n",
      "Epoch [98/100], Step [240/243], Loss: 0.0624\n",
      "\n",
      "train-loss: 1.3662, train-acc: 96.9120\n",
      "validation loss: 1.8012, validation acc: 71.4286\n",
      "\n",
      "Epoch 99\n",
      "\n",
      "Epoch [99/100], Step [0/243], Loss: 0.0323\n",
      "Epoch [99/100], Step [20/243], Loss: 0.0159\n",
      "Epoch [99/100], Step [40/243], Loss: 0.3336\n",
      "Epoch [99/100], Step [60/243], Loss: 0.0807\n",
      "Epoch [99/100], Step [80/243], Loss: 0.0568\n",
      "Epoch [99/100], Step [100/243], Loss: 0.0397\n",
      "Epoch [99/100], Step [120/243], Loss: 0.0310\n",
      "Epoch [99/100], Step [140/243], Loss: 0.0210\n",
      "Epoch [99/100], Step [160/243], Loss: 0.0286\n",
      "Epoch [99/100], Step [180/243], Loss: 0.3017\n",
      "Epoch [99/100], Step [200/243], Loss: 0.6920\n",
      "Epoch [99/100], Step [220/243], Loss: 0.0391\n",
      "Epoch [99/100], Step [240/243], Loss: 0.0325\n",
      "\n",
      "train-loss: 1.3537, train-acc: 97.2723\n",
      "validation loss: 1.7933, validation acc: 70.6767\n",
      "\n",
      "Epoch 100\n",
      "\n",
      "Epoch [100/100], Step [0/243], Loss: 0.2177\n",
      "Epoch [100/100], Step [20/243], Loss: 0.0410\n",
      "Epoch [100/100], Step [40/243], Loss: 0.0526\n",
      "Epoch [100/100], Step [60/243], Loss: 0.1020\n",
      "Epoch [100/100], Step [80/243], Loss: 0.0809\n",
      "Epoch [100/100], Step [100/243], Loss: 0.0934\n",
      "Epoch [100/100], Step [120/243], Loss: 0.4844\n",
      "Epoch [100/100], Step [140/243], Loss: 0.0631\n",
      "Epoch [100/100], Step [160/243], Loss: 0.0518\n",
      "Epoch [100/100], Step [180/243], Loss: 0.0285\n",
      "Epoch [100/100], Step [200/243], Loss: 0.1139\n",
      "Epoch [100/100], Step [220/243], Loss: 0.1141\n",
      "Epoch [100/100], Step [240/243], Loss: 0.0197\n",
      "\n",
      "train-loss: 1.3413, train-acc: 97.5296\n",
      "validation loss: 1.7857, validation acc: 72.9323\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 100\n",
    "print_every = 10\n",
    "valid_loss_min = np.Inf\n",
    "val_loss = []\n",
    "val_acc = []\n",
    "train_loss = []\n",
    "train_acc = []\n",
    "total_step = len(train_dataloader)\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total=0\n",
    "    print(f'Epoch {epoch}\\n')\n",
    "    for batch_idx, (data_, target_) in enumerate(train_dataloader):\n",
    "        data_, target_ = data_.to('cuda'), target_.to('cuda')\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(data_)\n",
    "        loss = criterion(outputs, target_)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _,pred = torch.max(outputs, dim=1)\n",
    "        correct += torch.sum(pred==target_).item()\n",
    "        total += target_.size(0)\n",
    "        if (batch_idx) % 20 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch, n_epochs, batch_idx, total_step, loss.item()))\n",
    "    train_acc.append(100 * correct / total)\n",
    "    train_loss.append(running_loss/total_step)\n",
    "    print(f'\\ntrain-loss: {np.mean(train_loss):.4f}, train-acc: {(100 * correct/total):.4f}')\n",
    "    batch_loss = 0\n",
    "    total_t=0\n",
    "    correct_t=0\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for data_t, target_t in (test_dataloader):\n",
    "            data_t, target_t = data_t.to(device), target_t.to(device)\n",
    "            outputs_t = model(data_t)\n",
    "            loss_t = criterion(outputs_t, target_t)\n",
    "            batch_loss += loss_t.item()\n",
    "            _,pred_t = torch.max(outputs_t, dim=1)\n",
    "            correct_t += torch.sum(pred_t==target_t).item()\n",
    "            total_t += target_t.size(0)\n",
    "        val_acc.append(100 * correct_t/total_t)\n",
    "        val_loss.append(batch_loss/len(test_dataloader))\n",
    "        network_learned = batch_loss < valid_loss_min\n",
    "        print(f'validation loss: {np.mean(val_loss):.4f}, validation acc: {(100 * correct_t/total_t):.4f}\\n')\n",
    "\n",
    "        \n",
    "        if network_learned:\n",
    "            valid_loss_min = batch_loss\n",
    "            torch.save(model.state_dict(), 'C:/Datasets/new_rock/resnet.pt')\n",
    "            print('Improvement-Detected, save-model')\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ea4894",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b07f78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d1d944",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de62cbce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba678a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4338d65a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e7f4b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867e382b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0c4e97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9dc7e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, May 19 2022, 07:22:26)  [GCC 11.3.0 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "2a8dfe095fce2b5e88c64a2c3ee084c8e0e0d70b23e7b95b1cfb538be294c5c8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
